{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "athletic-defeat",
   "metadata": {},
   "source": [
    "# Zadania Lista 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1f52cc-4da1-4407-8d3f-b40e3ba16285",
   "metadata": {},
   "source": [
    "**Wymagania**\n",
    "\n",
    "- Końcową komendę `dvc repro` należy uruchomić korzystając ze środowiska w kontenerze Docker, w przeciwnym razie przyznane będzie 0pkt za zadania z DVC. \n",
    "- MLflow należy uruchomić w Dockerze, w przeciwnym razie przyznane będzie 0pkt za zadania z MLflow.\n",
    "\n",
    "---\n",
    "\n",
    "**Żródło danych**\n",
    "\n",
    "Będziemy korzystać ze zbioru danych Amazon Review Data, dokumentację znajdziemy [tutaj](https://nijianmo.github.io/amazon/index.html):\n",
    "* grupa 1 i 2:\n",
    "    - https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/Luxury_Beauty_5.json.gz\n",
    "* grupa 3 i 4 (pliki należy połączyć w ramach preprocessing'u, a kategorię jako wpisać jako nową kolumnę):\n",
    "    - https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/All_Beauty_5.json.gz\n",
    "    - https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/AMAZON_FASHION_5.json.gz\n",
    "    - https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/Appliances_5.json.gz\n",
    "    - https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/Software_5.json.gz\n",
    "    \n",
    "**Etykiety**\n",
    "* grupa 1 i 2: kolumna \"overall\", uproszczona następująco 1,2 -> \"negative\", 3 -> \"neutral\", 4,5 -> \"positive\"\n",
    "* grupa 3 i 4: kolumna \"overall\"\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-degree",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. (3 pkt) Przygotowanie potoku przetwarzaniadanych\n",
    "\n",
    "Przygotuj poszczególne elementy rozwiązania problemu uczenia maszynowego w postaci osobnych skryptów.\n",
    "\n",
    "Do realizacji zastosować następujący podział:\n",
    "- Wstępne przetwarzanie danych\n",
    "- Podział danych\n",
    "- Analiza danych\n",
    "- Ekstrakcja cech\n",
    "- Uczenie i ewaluacja modelu\n",
    "\n",
    "Skrypty umieść w folderze `scripts`, parametry w pliku `params.yaml`, a pliki wejściowe i wyjściowe w folderze `data`.\n",
    "\n",
    "W ramach tej listy zajmiemy się klasyfikatora, który będzie punktem odniesienia (baseline) w kolejnych listach. Będzie on predykował ignorując wszystkie cechy wejściowe. Ponieżej zamieszczono opis działania poszczególnych skryptów.\n",
    "\n",
    "- Wstępne przetwarzanie danych - jeśli nie będzie potrzebny to skrypt ma zapisywać dane dokładnie takie jakie są. **uwaga**: nie oznacza to, że etap może zostać pominięty\n",
    "- Podział danych - podziel dane na zbiory train/val/test bez stratyfikacji i je zapisz. Zaleca się wykorzystanie funkcji [sklearn.model_selection.train_test_split\n",
    "](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "- Ekstrakcja cech - usuń wszystkie cechy (poza klasą sentymentu) oraz dodaj nową kolumnę, którą całą wypełnisz wartością `None`. Zapisz wynik.\n",
    "- Analiza danych - na razie pomijamy, zajmiemy się na przyszłych zajęciach\n",
    "- Uczenie i ewaluacja modelu - wytrenuj klasyfikator który będzie predykował najczęstszą klasę, następnie policz F1-score, wyniki zapisz w formacie json. Zaleca się wykorzystanie [sklearn.dummy.DummyClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) oraz [sklearn.metrics.f1_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html).\n",
    "\n",
    "\n",
    "**Uwagi**\n",
    "* należy dobrze się zastanowić jakie parametry umieścić w `params.yaml`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-popularity",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. (3 pkt)  Obsługa DVC\n",
    "\n",
    "* Dodaj przygotowane skrypty jako elementy potoku `DVC`, zdefiniuj odpowiednie parametry, zależności oraz wyjścia.\n",
    "* Dodaj metryki do trackowania. \n",
    "* Zreprodukuj potok. Zatwierdź zmiany i umieść je w repozytorium. \n",
    "* Zmień podział danych na stratyfikowany. Zreprodukuj potok. Zatwierdź zmiany i umieść je w repozytorium. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-organ",
   "metadata": {},
   "source": [
    "## 3. (3 pkt) Wykonanie eksperymentów\n",
    "\n",
    "* Dodaj wsparcie dla modelu predykującego klasę z rozkładu jednostajnego ciągłego. Dodaj możliwość wybrania modelu w konfiguracji (params.yaml). \n",
    "* Dodaj logowanie tego modelu do mlflow. Wykorzystaj api `dvc experiments` do porównania modeli. \n",
    "* Załącz zrzuty ekranu z MLFlow pokazujące przebieg eksperymentów.\n",
    "* Załącz wyjście polecenia dvc experiments show.\n",
    "\n",
    "\n",
    "\n",
    "## 4. (3 pkt) Obsługa MLflow\n",
    "\n",
    "* Do skryptu przeznaczonego do ewaluacji modelu dodaj obsługę `MLflow`. \n",
    "* Przekaż odpowiednie parametry i metryki. \n",
    "* Dodaj wykres macierzy pomyłek dla zbioru uczącego i testowego.\n",
    "* Załącz zrzuty ekranu z MLFlow pokazujące przebieg eksperymentów\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d76f20-4be8-4ba0-9028-909ca6720507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

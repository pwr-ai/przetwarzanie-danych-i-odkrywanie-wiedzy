{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L5: Narzędzia zarządzania eksperymentami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W ramach materiałów zajmiemy się zagadnieniem analizy nacechowania wypowiedzi, dla którego zbudujemy potok przetwarzania dla tego zadania oraz wykorzystamy narzędzia do zarządzania eksperymentami: [DVC](https://dvc.org/) oraz [MLFlow](https://mlflow.org/). Na potrzeby laboratorium tym razem wykorzystamy zbiór [`clarin-pl/polemo2`](https://clarin-pl.eu/dspace/handle/11321/710), który jest również udostępniony na repozytorium [`huggingface`](https://huggingface.co/datasets/clarin-pl/polemo2-official). Zbiór `polemo2` jest przeznaczony do analizy nacechowania wypowiedzi zawiera 8216 recenzji napisanych w języku polskim pochodzących z różnych domen: `hotels` (tripadvisor.com), `medicne` (znanylekarz.com), `school` (polwro.pl), `products` (ceneo.pl). Do rencenzji przypisano cztery klasy nacechowania wypowiedzi:\n",
    "- zero - neutralna\n",
    "- minus - negatywna\n",
    "- plus - pozytywna\n",
    "- amb -  nieokreślona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DVC\n",
    "\n",
    "DVC można najkrócej opisać jako system kontroli wersji dla danych lub jako `git` dla danych i modeli. Jest to narzędzie o otwartych źródłach, które pozwala nam m.in.:\n",
    "- wersjonować dane i modele (do śledzenia wersji plików lub folderów dvc wykorzystuje sumy kontrolne `md5`)\n",
    "- zarządzać potokami przetwarzania i zapewnia interfejs do śledzenia metryk\n",
    "- przesyłać dane na zewnetrzne serwery oraz zarządzać nimi lokalnie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{important}\n",
    "DVC jest dalej w trakcie rozwoju, dlatego poniższa instrukcja ogranicza się do zastosowania DVC w wersji 2.x. Nowsze wersje biblioteki np. 3.x, mogą wprowadzić duże zmiany do poszczególnych funkcjonalności. Najnowsza wersja dokumentacji jest dostępna pod adresem https://dvc.org/doc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalacja\n",
    "\n",
    "DVC możemy najprościej zainstalować poprzez menadżera paczek pip\n",
    "\n",
    "```pip install dvc```\n",
    "\n",
    "Dodatkowo do obsługi zewnętrzych serwerów wymaga zainstalowania dodatkowych zależności. Wspierane konfiguracje to `s3, gs, azure, oss, ssh` lub `all` - instaluje wszystkie opcjonalne zależności. Jeżeli chcemy zainstalować dodatkowe zależności np. dla s3, polecenie przyjmie następującą postać:\n",
    "\n",
    "```pip install dvc[s3]```\n",
    "\n",
    "W ramach materiałów nie będziemy wykorzystywać zewnętrznego serwera, dlatego wystarczy nam podstawowa wersja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{important}\n",
    "\n",
    "Poniższa instrukcja dotyczy wykorzystania DVC w wersji 2.0 i została przetestowana z wykorzystaniem wersji 2.1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicjalizacja repozytorium dvc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicjalizacja repozytorium dvc występuję z wykorzystaniem komendy `dvc init`, przechodząc do głównego katalogu projektu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```console\n",
    "$ dvc init\n",
    "\n",
    "Initialized DVC repository.\n",
    "\n",
    "You can now commit the changes to git.\n",
    "\n",
    "+---------------------------------------------------------------------+\n",
    "|                                                                     |\n",
    "|        DVC has enabled anonymous aggregate usage analytics.         |\n",
    "|     Read the analytics documentation (and how to opt-out) here:     |\n",
    "|             <https://dvc.org/doc/user-guide/analytics>              |\n",
    "|                                                                     |\n",
    "+---------------------------------------------------------------------+\n",
    "\n",
    "What's next?\n",
    "------------\n",
    "- Check out the documentation: <https://dvc.org/doc>\n",
    "- Get help and share ideas: <https://dvc.org/chat>\n",
    "- Star us on GitHub: <https://github.com/iterative/dvc>\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{important}\n",
    "`dvc init` domyślnie wykonuje inicjalizację w głównym folderze, jeżeli chcemy umieścić go poza głównym folderem   musimy skorzystać z flagi `--subdir`. Pełną listę konfiguracji komendy `dvc init` znajdziemy w dokumentacji. [LINK](https://dvc.org/doc/command-reference/init)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy, jakie pliki są śledzone przez `git`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```console\n",
    "$ git status\n",
    "On branch main\n",
    "Your branch is up to date with 'origin/main'.\n",
    "\n",
    "Changes to be committed:\n",
    "  (use \"git reset HEAD <file>...\" to unstage)\n",
    "\n",
    "        new file:   .dvc/.gitignore\n",
    "        new file:   .dvc/config\n",
    "        new file:   .dvc/plots/confusion.json\n",
    "        new file:   .dvc/plots/confusion_normalized.json\n",
    "        new file:   .dvc/plots/default.json\n",
    "        new file:   .dvc/plots/linear.json\n",
    "        new file:   .dvc/plots/scatter.json\n",
    "        new file:   .dvc/plots/smooth.json\n",
    "        new file:   .dvcignore\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pliki trackowane przez repozytorium git\n",
    "\n",
    "- `.dvc/.gitignore` - Deklaracja plików/folderów, które mają nie być trackowane przez gita\n",
    "- `.dvc/config` - Konfiguracja dvc, tutaj umieszczana jest np. konfiguracja zewnętrznego serwera\n",
    "- `.dvc/plots/*.json` - Szablony dla wykresów udostępnianych przez dvc. Więcej informacji: [[LINK]](https://dvc.org/doc/command-reference/plots)\n",
    "- `.dvcignore` - Deklaracja plików/folderów, która mają nie być trackowane przez dvc\n",
    "\n",
    "Pliki nietrackowane przez git:\n",
    "- `.dvc/cache/` - Folder cache, tutaj zawierają się lokalne pliki repozytorium. Więcej informacji: [[LINK]](https://dvc.org/doc/user-guide/project-structure/internal-files#structure-of-the-cache-directory)\n",
    "- `.dvc/tmp/` - Pliki tymczasowe\n",
    "\n",
    "Szczegółowy opis plików znajduje się pod adresem: [[LINK]](https://dvc.org/doc/user-guide/project-structure/internal-files#structure-of-the-cache-directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dodanie pierwszego etapu potoku przetwarzania do DVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Przygotowanie skryptu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najpierw zaczniemy od przygotowania skryptu do pobrania zbioru danych. Konfigurację dla tego skryptu umieścimy w zewnętrzntym pliku `params.yaml` w głównym katalogu. Parametrami skryptu będą domeny dla danego podziału danych (train, dev i test) oraz typ tekstów (zdania lub pełne recenzje). Działanie tego skryptu będzie polegać na pobraniu odpowiedniej konfiguracji zbioru danych z repozytorium i jego transformacja go do prostszego formatu. Przetworzony plik umieśćmy w folderze `data/`\n",
    "\n",
    "`scripts/download_data.py`\n",
    "\n",
    "```python\n",
    "\n",
    "import pickle\n",
    "\n",
    "import datasets\n",
    "import yaml\n",
    "\n",
    "\n",
    "def main():\n",
    "    with open(\"params.yaml\", \"r\") as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "\n",
    "    dataset = datasets.load_dataset(\n",
    "        \"clarin-pl/polemo2-official\", **cfg[\"download_data\"]\n",
    "    )\n",
    "\n",
    "    dataset = {\n",
    "        \"train\": (dataset[\"train\"][\"text\"], dataset[\"train\"][\"target\"]),\n",
    "        \"validation\": (dataset[\"validation\"][\"text\"], dataset[\"validation\"][\"target\"]),\n",
    "        \"test\": (dataset[\"test\"][\"text\"], dataset[\"test\"][\"target\"]),\n",
    "    }\n",
    "\n",
    "    with open(\"data/dataset.pkl\", \"wb\") as f:\n",
    "        pickle.dump(obj=dataset, file=f)\n",
    "\n",
    "\n",
    "main()\n",
    "```\n",
    "\n",
    "Jako domyślną konfigurację wykorzystajmy recenzje pochodzące z hoteli i zdania.\n",
    "\n",
    "`params.yaml`\n",
    "```yaml\n",
    "download_data:\n",
    "  train_domains:\n",
    "    - hotels\n",
    "  dev_domains:\n",
    "    - hotels\n",
    "  test_domains:\n",
    "    - hotels\n",
    "  text_cfg: sentence\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dodanie skryptu do DVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etapy przetwarzania dodajemy do potoku za pomocą komendy `dvc run` [[LINK]](https://dvc.org/doc/command-reference/run) lub `dvc stage add` [[LINK]](https://dvc.org/doc/command-reference/stage/add).\n",
    "\n",
    "Głównymi elementami danego etapu definiowanego w dvc są:\n",
    "- zależności etapu (dane wejściowe, skrypty pythonowe etc.), definiowane za pomocą parametru `-d`\n",
    "- parametry (w celu śledzenia zmian), definiowane za pomocą parametru `-p`\n",
    "- pliki wyjściowe, definiowane za pomocą parametru `-o`\n",
    "- skrypt który będziemy wykonywać podawany na końcu polecania w naszym przypadku będzie to `python3 scripts/download_data.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wróćmy do naszego skryptu pobierającego zbiór danych. Nazwę etapu przypisujemy za pomocą parametru `-n`. \n",
    "\n",
    "```{important}\n",
    "Etapy w dvc podczas dodawania za pomocą `dvc run` są automatycznie wykonywane, aby zmienić to zachowanie musimy dodać flagę `--no-exec` lub możemy wykorzystać polecenie `dvc stage add`\n",
    "```\n",
    "\n",
    "Zdefiniujmy teraz elementy etapu:\n",
    "- Zależności: \n",
    "    - Skrypt `scripts/download_data.py`\n",
    "- Parametry:\n",
    "    - train_domains\n",
    "    - test_domains\n",
    "    - dev_domains\n",
    "    - text_cfg\n",
    "- Wyjście:\n",
    "    - Plik `data/dataset.pkl`\n",
    "- Skrypt do wykonania: `PYTHONPATH=. python3 scripts/download_data.py`\n",
    "\n",
    "Zbierzmy teraz wszystko w ramach polecenia i wykonajmy je.\n",
    "```console\n",
    "$ dvc run  \\\n",
    "    -n download_data \\\n",
    "    -d scripts/download_data.py \\\n",
    "    -o data/dataset.pkl \\\n",
    "    -p download_data.train_domains \\\n",
    "    -p download_data.dev_domains \\\n",
    "    -p download_data.test_domains \\\n",
    "    -p download_data.text_cfg \\\n",
    "    --no-exec \\\n",
    "    PYTHONPATH=. python3 scripts/download_data.py\n",
    "\n",
    "Creating 'dvc.yaml'                                                   \n",
    "Adding stage 'download_data' in 'dvc.yaml'\n",
    "\n",
    "To track the changes with git, run:\n",
    "\n",
    "        git add data/.gitignore dvc.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{important}\n",
    "Przy pracy z repozytorium DVC szczególną uwagę należy zwrócić na pliki `.gitignore` generowane podczas dodawania następnych etapów. Pozwala to uniknąć dodania nieporządanych plików do repozytorium git.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{important}\n",
    "\n",
    "Plik `params.yaml` umieszczony w głównym katalogu repozytorium lub w odpowiednim podfolderze, jeżeli dvc było inicjalizowane z flagą --subdir jest domyślną ścieżką do definicji parametrów w dvc. Pozwala to na odwoływanie się do parametrów umieszczonych w tym pliku bezpośrednio. Jeżeli nasza konfiguracja byłaby w innej lokalizacji np.  w `configs/download_data.yaml` musielibyśmy ją podać. Przykładowa dekleracja parametru miałaby wtedy postać\n",
    "`-p configs/download_data.yaml:train_domains`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wszystkie elementy potoku przetwarzania są definiowane w pliku `dvc.yaml`. Spójrzmy na jego sygnaturę w tym momencie.\n",
    "\n",
    "`dvc.yaml`\n",
    "```yaml\n",
    "stages:\n",
    "  download_data:\n",
    "    cmd: PYTHONPATH=. python3 scripts/download_data.py\n",
    "    deps:\n",
    "    - scripts/download_data.py\n",
    "    params:\n",
    "    - download_data.dev_domains\n",
    "    - download_data.test_domains\n",
    "    - download_data.text_cfg\n",
    "    - download_data.train_domains\n",
    "    outs:\n",
    "    - data/dataset.pkl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{hint}\n",
    "Kolejne etapy możemy również dodawać lub edytować bezpośrednio modyfikąc plik `dvc.yaml`. Jednak wtedy musimy sami zadbać o poprawność definicji oraz o zarządzanie plikami `.gitignore\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sprawdzenie statusu potoku\n",
    "\n",
    "Stan potoku możemy sprawdzić za pomocą polecenia `dvc status`. Daje nam to pogląd na zmiany, które występują w naszym potoku. \n",
    "\n",
    "```console\n",
    "$ dvc status\n",
    "\n",
    "download_data:                                                        \n",
    "        changed deps:\n",
    "                modified:           scripts/download_data.py\n",
    "                params.yaml:\n",
    "                        new:                download_data.dev_domains\n",
    "                        new:                download_data.test_domains\n",
    "                        new:                download_data.text_cfg\n",
    "                        new:                download_data.train_domains\n",
    "        changed outs:\n",
    "                deleted:            data/dataset.pkl\n",
    "```\n",
    "\n",
    "W tym przypadku `dvc status` pokazuje nam w naszym etapie `download_data` tutaj zmiany zarówno w zależnościach, parametrach jak i w pliku wyjściowym. \n",
    "\n",
    "\n",
    "#### Wykonywanie etapów\n",
    "\n",
    "Do wykonania etapu lub etapów służy polecenie `dvc repro`. Domyślna konfiguracja polecenia `dvc repro` oznacza przejrzenie całego potoku i wykonanie tylko tych etapów w których wykryto zmiany. Możemy również wykonać jeden etap lub wybraną część potoku przekazując nazwy etapów. Pełna dokumentacja: [[LINK]](https://dvc.org/doc/command-reference/repro)\n",
    "\n",
    "\n",
    "Przydatne parametry:\n",
    "- `--dry` - pozwala podejrzeć które etapy mają byc wykonane\n",
    "- `-f` - wymuszenie wykonania wszystkich lub wybranych potoków, nawet jeżeli `dvc` nie reportuje zmian\n",
    "- `-s` - wykonanie pojedynczego etapu z pominięciem poprzednich, nawet jeżeli `dvc` reportuje zmiany\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykonujmy teraz reprodukcję potoku\n",
    "\n",
    "```console\n",
    "$ dvc repro\n",
    "\n",
    "Running stage 'download_data':                                        \n",
    "> PYTHONPATH=. python3 scripts/download_data.py\n",
    "Using custom data configuration default-d3f574c876938804\n",
    "Reusing dataset pol_emo2\n",
    "Generating lock file 'dvc.lock'                                       \n",
    "Updating lock file 'dvc.lock'\n",
    "\n",
    "To track the changes with git, run:\n",
    "\n",
    "        git add dvc.lock\n",
    "Use `dvc push` to send your updates to remote storage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stan potoku jest zapisywany w pliku dvc.lock\n",
    "\n",
    "```yaml\n",
    "\n",
    "schema: '2.0'\n",
    "stages:\n",
    "  download_data:\n",
    "    cmd: PYTHONPATH=. python3 scripts/download_data.py\n",
    "    deps:\n",
    "    - path: scripts/download_data.py\n",
    "      md5: 79bddadefd2d6422e47f5b9190b1e26e\n",
    "      size: 585\n",
    "    params:\n",
    "      params.yaml:\n",
    "        download_data.dev_domains:\n",
    "        - hotels\n",
    "        download_data.test_domains:\n",
    "        - hotels\n",
    "        download_data.text_cfg: sentence\n",
    "        download_data.train_domains:\n",
    "        - hotels\n",
    "    outs:\n",
    "    - path: data/dataset.pkl\n",
    "      md5: 5bd49b39290147a1cfd193b4356890d0\n",
    "      size: 2524424\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wysyłanie i pobieranie danych z dvc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{important}\n",
    "Wymaga konfiguracji serwera zewnętrznego.\n",
    "Więcej szczegółów na temat konfiguracji serwera:  [[LINK]](https://dvc.org/doc/command-reference/remote)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pliki śledzone przez dvc takie jak np. pliki wyjściowe możemy przesyłać na zewnętrzny serwer za pomocą polecenia\n",
    "`dvc push`, a pobierać lokalnie za pomocą komendy `dvc pull`. Podobnie jak w przypadku `dvc repro` zakres operacji `push` i `pull` obejmuje domyślnie cały potok lub jego wybraną część poprzez przekazanie nazw(y) etapów jako argumentu polecenia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolejne etapy przetwarzania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodajmy teraz kolejne etapy przetwarzania [extract_features](https://github.com/pwr-ai/przetwarzanie-danych-i-odkrywanie-wiedzy/blob/7fdd74b21c92bac61bfefca949b4d34bc6c70c20/examples/lab5/scripts/extract_features.py) i [evaluate_model](https://github.com/pwr-ai/przetwarzanie-danych-i-odkrywanie-wiedzy/blob/7fdd74b21c92bac61bfefca949b4d34bc6c70c20/examples/lab5/scripts/evaluate_model.py). Odpowiednie parametry zostały dodane do pliku `params.yaml`. \n",
    "\n",
    "`extract_features` dodamy podobnie jak wcześniej `download_data`\n",
    "\n",
    "```console\n",
    "$ dvc run  \\\n",
    "    -n extract_features \\\n",
    "    -d scripts/extract_features.py \\\n",
    "    -d data/dataset.pkl \\\n",
    "    -o data/featurized.pkl \\\n",
    "    --no-exec \\\n",
    "    PYTHONPATH=. python3 scripts/extract_features.py\n",
    "    \n",
    "Adding stage 'extract_features' in 'dvc.yaml'                         \n",
    "\n",
    "To track the changes with git, run:\n",
    "\n",
    "        git add dvc.yaml data/.gitignore\n",
    "```\n",
    "\n",
    "    \n",
    "W przypadku `evaluate_model` dodamy mechanizm śledzenie metryk. Pełny opis jest dostępny pod adresem [[LINK]](https://dvc.org/doc/command-reference/metrics). Metryki specyfikuje się za pomocą flagi `-M`. Obecnie wspierany jest format `json` lub `yaml`. \n",
    "\n",
    "```console\n",
    "$ dvc run  \\\n",
    "    -n evaluate_model \\\n",
    "    -d scripts/evaluate_model.py \\\n",
    "    -d data/featurized.pkl \\\n",
    "    -M data/results.json \\\n",
    "    -p evaluate_model.random_state \\\n",
    "    -p evaluate_model.max_iter \\\n",
    "    --no-exec \\\n",
    "    PYTHONPATH=. python3 scripts/evaluate_model.py\n",
    "\n",
    "Adding stage 'evaluate_model' in 'dvc.yaml'                           \n",
    "\n",
    "To track the changes with git, run:\n",
    "\n",
    "        git add dvc.yaml\n",
    "```\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zreprodukujmy teraz cały potok\n",
    "\n",
    "```console\n",
    "$ dvc repro\n",
    "\n",
    "Stage 'download_data' didn't change, skipping                         \n",
    "Running stage 'extract_features':\n",
    "> PYTHONPATH=. python3 scripts/extract_features.py\n",
    "Updating lock file 'dvc.lock'                                         \n",
    "\n",
    "Running stage 'evaluate_model':\n",
    "> PYTHONPATH=. python3 scripts/evaluate_model.py\n",
    "Updating lock file 'dvc.lock'                                         \n",
    "\n",
    "To track the changes with git, run:\n",
    "\n",
    "        git add dvc.lock\n",
    "Use `dvc push` to send your updates to remote storage.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przeglądanie potoku przetwarzania, parametrów i metryk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mając już zdefiniowany potok przetwarzania możemy go zwizualizować w konsoli za pomocą komendy `dvc dag` [[LINK]](https://dvc.org/doc/command-reference/dag)\n",
    "\n",
    "```console\n",
    "\n",
    "$ dvc dag\n",
    "\n",
    "  +---------------+  \n",
    "  | download_data |  \n",
    "  +---------------+  \n",
    "          *          \n",
    "          *          \n",
    "          *          \n",
    "+------------------+ \n",
    "| extract_features | \n",
    "+------------------+ \n",
    "          *          \n",
    "          *          \n",
    "          *          \n",
    " +----------------+  \n",
    " | evaluate_model |  \n",
    " +----------------+  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy również śledzić graph zależności pomiędzy wyjściami za pomocą flagi `--outs`\n",
    "\n",
    "\n",
    "```console\n",
    "$ dvc dag --outs\n",
    "\n",
    "  +------------------+   \n",
    "  | data/dataset.pkl |   \n",
    "  +------------------+   \n",
    "            *            \n",
    "            *            \n",
    "            *            \n",
    "+---------------------+  \n",
    "| data/featurized.pkl |  \n",
    "+---------------------+  \n",
    "            *            \n",
    "            *            \n",
    "            *            \n",
    " +-------------------+   \n",
    " | data/results.json |   \n",
    " +-------------------+   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listę etapów możemy podejrzeć za pomocą polecenia `dvc stage list` [[LINK]](https://dvc.org/doc/command-reference/stage/list)\n",
    "\n",
    "```console\n",
    "$ dvc stage list\n",
    "download_data     Outputs data/dataset.pkl\n",
    "extract_features  Outputs data/featurized.pkl\n",
    "evaluate_model    Reports data/results.json\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metryki możemy teraz wyświetlić bezpośrednio z konsoli za pomocą komendy `dvc metrics show` [[LINK]](https://dvc.org/doc/command-reference/metrics/show)\n",
    "\n",
    "```console\n",
    "$ dvc metrics show\n",
    "Path               accuracy    f1-score                               \n",
    "data/results.json  0.74165     0.67661\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametry możemy wyświetlić za pomocą `dvc params diff --all` [[LINK]](https://dvc.org/doc/command-reference/params/diff)\n",
    "\n",
    "```console\n",
    "$ dvc params diff --all\n",
    "\n",
    "Path         Param                        Old         New             \n",
    "params.yaml  download_data.dev_domains    ['hotels']  ['hotels']\n",
    "params.yaml  download_data.test_domains   ['hotels']  ['hotels']\n",
    "params.yaml  download_data.text_cfg       sentence    sentence\n",
    "params.yaml  download_data.train_domains  ['hotels']  ['hotels']\n",
    "params.yaml  evaluate_model.max_iter      200         200\n",
    "params.yaml  evaluate_model.random_state  441         441\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wprowadzanie tymczasowych zmian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czasami potrzebujemy wprowadzić szybkie zmiany, ale niekoniecznie chcemy je przesłać później na repozytorium. W celu ćwiczenia zmieńmy parametry `download_data.text_cfg` na `text` oraz `evaluate_model.max_iter` na `50`.\n",
    "\n",
    "Zmiany możemy sprawdzić za również za pomocą `dvc params diff`.\n",
    "\n",
    "```console\n",
    "$ dvc params diff\n",
    "\n",
    "Path         Param                    Old       New                   \n",
    "params.yaml  download_data.text_cfg   sentence  text\n",
    "params.yaml  evaluate_model.max_iter  200       50\n",
    "```\n",
    "\n",
    "Zamiast wszystkich elementów, polecenie teraz wyświetla nam tylko te w których dokonana byłą zmiana.\n",
    "\n",
    "Parametry się zgadzają, dokonajmy reprodukcji całego potoku za pomocą `dvc repro`. Zmiany wymagają wykonania całego potoku od nowa.\n",
    "\n",
    "Po wykonaniu się wszystkich elementu potoku, możemy sprawdzić zmiany.ożemy sprawdzić jak zmieniły się metryki do tego wykorzystamy polecenia `dvc metrics diff`\n",
    "\n",
    "```console\n",
    "$ dvc metrics diff\n",
    "\n",
    "Path               Metric    Old      New      Change                 \n",
    "data/results.json  accuracy  0.74165  0.81013  0.06848\n",
    "data/results.json  f1-score  0.67661  0.80187  0.12526\n",
    "```\n",
    "\n",
    "Czas na cofnięcie zmian, zacznijmy od odrzucenia zmian w repozytorium git, zmienione pliki to `results.json`, `params.yaml` i `dvc.lock`. \n",
    "\n",
    "```console\n",
    "$ git restore .\n",
    "```\n",
    "\n",
    "Teraz zostaje nam cofnięcie zmian w plikach `dvc` do tego wykorzystamy komendę `checkout`, która działa w podobny sposób jak `git checkout`. Przydatna jest również w sytuacji, kiedy przełączamy się pomiędzy różnymi branchami.\n",
    "\n",
    "```console\n",
    "$ dvc checkout\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inne przydatne komendy DVC \n",
    "\n",
    "- [dvc add](https://dvc.org/doc/command-reference/add) - Pozwala na śledzenie pliku / folderu poprzez utworzenie pliku `{nazwa_pliku}.dvc`.  \n",
    "Przykład\n",
    "\n",
    "```console\n",
    "$ dvc add data/\n",
    "```\n",
    "\n",
    "`data.dvc`\n",
    "```yaml\n",
    "outs:\n",
    "- md5: 48c6715169a5ed3b78e278f5f2c6055e.dir\n",
    "  size: 57675468\n",
    "  nfiles: 9\n",
    "  path: data\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "- [dvc commit](https://dvc.org/doc/command-reference/commit) - Pozwala uaktalnić stan danego etapu. `dvc commit` jest szczególnie przydatny w sytuacjach:\n",
    "    - Kiedy wprowadziliśmy zmiany w zależnościach etapu, które nie mają wpływu na pliki wyjściowe etapu\n",
    "    - Kiedy wykonaliśmy skrypt danego etapu z pominięciem polecenia `dvc repro`\n",
    "\n",
    "- [dvc remove](https://dvc.org/doc/command-reference/remove) - Usuwa dany etap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kod do części I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kompletny kod znajduje się pod adresem: [[LINK]](https://github.com/pwr-ai/przetwarzanie-danych-i-odkrywanie-wiedzy/tree/7fdd74b21c92bac61bfefca949b4d34bc6c70c20/examples/lab5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLFlow\n",
    "\n",
    "MLFlow jest również dedykowanym narzędziem do zarządzania eksperymentami. Jego funkcjonalnośc obejmuje następujące moduły:\n",
    "- [`MLFlow Tracking`](https://www.mlflow.org/docs/latest/tracking.html) - zarządzanie eksperymentami, logowanie parametrych, metryk, wykresów i innych artefaktów\n",
    "- [`MLFlow Projects`](https://www.mlflow.org/docs/latest/projects.html) - przygotowanie środowiska eksperymentalnego dla projektu, wykonywanie eksperymentów\n",
    "- [`MLFlow Deployment`](https://www.mlflow.org/docs/latest/models.html) - Wdrażanie modeli\n",
    "- [`MLFlow Registry`](https://www.mlflow.org/docs/latest/model-registry.html) - Rejestr modeli\n",
    "\n",
    "**Dokumentacja**: [[LINK]](https://www.mlflow.org/docs/latest/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W ramach zajęć skupimy się na module `MLFlow Tracking`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instalacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biblioteka mlflow również możemy zainstalować za pomocą menadżera paczek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "pip install mlflow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLFlow Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moduł jest oparty o monitorowanie przebiegów uczenia (ang. runs), które opcjonalnie możemy grupować w eksperymenty.\n",
    "\n",
    "W ramach pojedynczego przebiegu zbierane są takie komponenty jak:\n",
    "- Wersja kodu (aktualny hash commitu z gita)\n",
    "- Czas rozpoczęcia i zakończenia przebiegu\n",
    "- Źródło uruchomienia np. nazwa skryptu do uczenia \n",
    "- Parametry\n",
    "- Metryki\n",
    "- Artefakty - pliki wyjściowe w dowolnym formacie, można logować obrazy, wykresy, modele itp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do logowania eksperymenty potrzebujemy zdefiniowania dwóch magazynów danych:\n",
    "  - `backend store` - przechowuje dane dotyczące ekspetymentów (przebiegi, parametry, metryki, tagi, metadane itp.)  \n",
    "  Wspierane typy magazynów danych:\n",
    "      - lokalna ścieżka\n",
    "      - baza danych: mysql, mssql, sqlite lub postgresql\n",
    "      \n",
    "  - `artifact store` - przechowuje artefakty (pliki, modele, wykresy, obrazy itp.)\n",
    "    Wspierane typy magazynów danych: lokalna ścieżka, Amazon S3, Azure Blob Storage, Google Cloud Storage, serwer FTP i SFTP, NFS i HDFS\n",
    "\n",
    "Więcej informacji na temat magazynów danych mlflow: [[LINK]](https://www.mlflow.org/docs/latest/tracking.html#backend-stores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ustawienia potrzebne do relizacji laboratorium\n",
    "\n",
    "W ramach laboratorium wykorzystamy baze danych sqllite, a artefakty będziemy logować do folderu `artifacts`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uruchomienie serwera do śledzenia przebiegów uczenia\n",
    "\n",
    "Pierwszym krokiem, który musimy zdefiniować jest uruchomienie serwera, który będzie nam obsługiwał proces śledzenia przebiegów uczenia. Do tego wykorzystamy komendę `mlflow server`. Aplikacja domyślnie uruchamia się na porcie 5000. Szczegółowa dokumentacja: [[LINK]](https://mlflow.org/docs/latest/tracking.html#tracking-server)\n",
    "```console\n",
    "$ mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./artifacts --host 0.0.0.0    \n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnym krokiem jest przekazanie adresu serwisu do śledzenia do biblioteki mlflow.\n",
    "Możemy umieścić bezpośrednie odwołanie w kodzie:\n",
    "```python\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "```\n",
    "\n",
    "lub za pomocą zmiennej środowiskowej\n",
    "```bash\n",
    "MLFLOW_TRACKING_URI=http://localhost:5000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitorowanie przebiegów uczenia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nowy przebieg tworzymy za pomocą metody [`mlflow.start_run()`](`https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.create_experiment). Najprościej jest umieścić go w ramach bloku kodu `with`.\n",
    "\n",
    "```python\n",
    "\n",
    "with mlflow.start_run():\n",
    "    ...\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatyczne logowanie\n",
    "\n",
    "MLflow dostarcza moduły, które pozwolają automatycznie logować parametry, sam model oraz metryki, odbywa się to za pomocą metody `autolog()`. Metoda `autolog()` musi być wywołana przed rozpocząciem procesu uczenia.\n",
    "\n",
    "```{important}\n",
    "Funkcjanolność związana z autologowaniem za pomocą metody autolog() jest w fazie eksperymentalnej i zależy od wykorzystywanej biblioteki.\n",
    "```\n",
    "\n",
    "Autolog obecnie nie wspiera automatycznego wykrywania modelu, musimy zaimportować odpowiedni moduł przeznaczony dla naszego modelu. W naszym przypadku będzie to sklearn. `mlflow.sklearn.autolog()`. \n",
    "\n",
    "Szczegóły dotyczące autologowania i lista obecnie wspieranych bibliotek znajduję się pod linkiem: [[LINK]](https://www.mlflow.org/docs/latest/tracking.html#automatic-logging)\n",
    "\n",
    "Autolog w przypadku `sklearn` loguje metryki wyłącznie dla danych uczących dla danych testowych lub walidacyjnych również to wykonać. Do tego wykorzystamy funkcję `mlflow.sklearn.eval_and_log_metrics`\n",
    "\n",
    "\n",
    "#### Ręczne logowanie \n",
    " \n",
    " - Logowanie parametrów: `mlflow.log_param` lub `mlflow.log_params`  \n",
    "Przykłady:\n",
    "    - `mlflow.log_param(\"train_domains\", cfg[\"download_data\"][\"train_domains\"])`\n",
    "    - `mlflow.log_params(cfg[\"download_data\"])`\n",
    "\n",
    "\n",
    "- Logowanie metryk `mlflow.log_metric` lub `mlflow.log_metrics`  \n",
    "Przykłady:  \n",
    "    - `mlflow.log_metric(\"accuracy\", metrics[\"accuracy\"])`   \n",
    "    - `mlflow.log_metrics(metrics=metrics)`\n",
    "    \n",
    "    \n",
    "- Logowanie wykresów `mlflow.log_figure`\n",
    "Przykłady:\n",
    "    - `mlflow.log_figure(fig, artifact_file=\"metrics.png\")`\n",
    "    \n",
    "    \n",
    "    \n",
    "- Logowanie modeli `mlflow.{moduł_wykorzystywanej_biblioteki}.log_model`\n",
    "Przykłady:\n",
    "    -  `mlflow.sklearn.log_model(clf, \"model\", registered_model_name=\"LogisticRegression\")`\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dodanie MLFlow do skryptu "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodajmy teraz obsługę mlflow do wcześniej przygotowane skryptu `evaluate_model`.\n",
    "\n",
    "Elementy, które będziemy logować:\n",
    "- autologowanie \n",
    "- logowanie parametru `train_domains` i `test_domains`\n",
    "- logowanie metryk `accuracy` i macro `f1-score` \n",
    "- logowanie wykresu przedstawiającego metryki `precision`, `recall`, `f1-score` per klasa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bazowa wersja skryptu `evaluate_model`\n",
    "```python\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import yaml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def main():\n",
    "    with open(\"data/featurized.pkl\", \"rb\") as f:\n",
    "        dataset = pickle.load(f)\n",
    "\n",
    "    with open(\"params.yaml\", \"r\") as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "\n",
    "    clf = LogisticRegression(**cfg[\"evaluate_model\"])\n",
    "    clf.fit(dataset[\"train\"][\"X\"], dataset[\"train\"][\"y\"])\n",
    "\n",
    "    y_pred = clf.predict(dataset[\"test\"][\"X\"])\n",
    "\n",
    "    report = classification_report(\n",
    "        y_pred=y_pred, y_true=dataset[\"test\"][\"y\"], output_dict=True\n",
    "    )\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": report[\"accuracy\"],\n",
    "        \"f1-score\": report[\"macro avg\"][\"f1-score\"],\n",
    "    }\n",
    "    with open(\"data/results.json\", \"w\") as f:\n",
    "        json.dump(obj=metrics, fp=f)\n",
    "\n",
    "\n",
    "main()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kod po dodaniu obsługi mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```diff\n",
    "import json\n",
    "import pickle\n",
    "+ from typing import Dict, Any, List\n",
    "\n",
    "+ import matplotlib.pyplot as plt\n",
    "+ import mlflow\n",
    "+ import pandas as pd\n",
    "+ import seaborn as sns\n",
    "import yaml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "+ def plot_metrics_per_class(report: Dict[str, Any], labels: List[str]):\n",
    "+    report = pd.DataFrame(\n",
    "+        [\n",
    "+            {\n",
    "+                \"class\": labels[class_id],\n",
    "+                \"metric\": metric,\n",
    "+                \"value\": report[str(class_id)][metric],\n",
    "+            }\n",
    "+            for class_id in range(len(labels))\n",
    "+            for metric in [\"precision\", \"recall\", \"f1-score\"]\n",
    "+        ]\n",
    "+    )\n",
    "+\n",
    "+    sns.barplot(data=report, x=\"class\", y=\"value\", hue=\"metric\")\n",
    "+\n",
    "+    plt.title(\"Metrics per class\")\n",
    "+    fig = plt.gcf()\n",
    "+    return fig\n",
    "\n",
    "\n",
    "def main():\n",
    "    with open(\"data/featurized.pkl\", \"rb\") as f:\n",
    "        dataset = pickle.load(f)\n",
    "\n",
    "    with open(\"params.yaml\", \"r\") as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "\n",
    "+    mlflow.set_tracking_uri(\"http://localhost:5100\")\n",
    "\n",
    "+    with mlflow.start_run():\n",
    "+        mlflow.sklearn.autolog()\n",
    "\n",
    "        clf = LogisticRegression(**cfg[\"evaluate_model\"])\n",
    "        clf.fit(dataset[\"train\"][\"X\"], dataset[\"train\"][\"y\"])\n",
    "\n",
    "        y_pred = clf.predict(dataset[\"test\"][\"X\"])\n",
    "\n",
    "        report = classification_report(\n",
    "            y_pred=y_pred,\n",
    "            y_true=dataset[\"test\"][\"y\"],\n",
    "            output_dict=True,\n",
    "        )\n",
    "        metrics = {\n",
    "            \"accuracy\": report[\"accuracy\"],\n",
    "            \"f1-score\": report[\"macro avg\"][\"f1-score\"],\n",
    "        }\n",
    "\n",
    "+        fig = plot_metrics_per_class(report, labels=dataset[\"labels\"])\n",
    "+        mlflow.log_params(cfg[\"download_data\"])\n",
    "+        mlflow.log_metrics(metrics=metrics)\n",
    "+        mlflow.sklearn.eval_and_log_metrics(\n",
    "+            clf, X=dataset[\"test\"][\"X\"], y_true=dataset[\"test\"][\"y\"], prefix=\"test_\"\n",
    "+        )\n",
    "+        mlflow.log_figure(fig, artifact_file=\"metrics.png\")\n",
    "\n",
    "    with open(\"data/results.json\", \"w\") as f:\n",
    "        json.dump(obj=metrics, fp=f)\n",
    "\n",
    "\n",
    "main()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eksperymenty w DVC 2.0\n",
    "\n",
    "Ostatnim omawianym elementem jest definiowanie eksperymentów w ramach DVC w wersji 2.0\n",
    "Eksperymenty oparte są o moduł [`dvc exp`](https://dvc.org/doc/command-reference/exp) pozwalają na łatwą zmianę konfiguracji potoku przetwarzania oraz umożliwiają definicję kilku konfiguracji. Aktualny opis interfejsu `experiments` znajduje się pod adresem [[LINK]](https://dvc.org/doc/start/experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eksperymenty są uruchamiane za pomocą komendy `dvc exp run` [[LINK]](https://dvc.org/doc/command-reference/exp/run) zmienione parametry podajemy za pomocą flagi `-S`.\n",
    "\n",
    "Zmieńmy teraz liczbę iteracji na 50. \n",
    "\n",
    "```console\n",
    "$ dvc exp run -S evaluate_model.max_iter=50\n",
    "\n",
    "...\n",
    "\n",
    "Reproduced experiment(s): exp-b605e\n",
    "Experiment results have been applied to your workspace.\n",
    "\n",
    "To promote an experiment to a Git branch run:\n",
    "\n",
    "        dvc exp branch <exp>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz możemy podejrzeć zmainę metryk za pomocą `dvc exp diff`\n",
    "\n",
    "```console\n",
    "$ dvc exp diff\n",
    "\n",
    "Path               Metric    Value    Change\n",
    "data/results.json  accuracy  0.73964  -0.0020121\n",
    "data/results.json  f1-score  0.66816  -0.0084543\n",
    "\n",
    "Path         Param                    Value    Change\n",
    "params.yaml  evaluate_model.max_iter  50       -150\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatywnie możemy zdefiniować kolejkę eksperymentów i dopiero później je wykonać. Dodajmy teraz inne konfigurację. W celu zakolejkowania eksperymentu wykorzystujemy flagę `--queue`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```console\n",
    "$ dvc exp run --queue -S evaluate_model.max_iter=300 -S download_data.train_domains=\"[hotels,medicine]\" \n",
    "Queued experiment '8cebb8b' for future execution.\n",
    "$ dvc exp run --queue -S evaluate_model.max_iter=300 -S download_data.train_domains=\"[medicine,products]\" \n",
    "Queued experiment '2d09bcb' for future execution. \n",
    "$ dvc exp run --queue -S evaluate_model.max_iter=300 -S download_data.train_domains=\"[all]\"\n",
    "Queued experiment 'cee43ab' for future execution. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uruchumienie eksperymentów\n",
    "```console\n",
    "$ dvc exp run --run-all \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podsumowanie wyników eksperymentów możemy uzyskać za pomocą polecenia `dvc exp show` [[LINK]](https://dvc.org/doc/command-reference/exp/show)\n",
    "```console\n",
    "$ dvc exp show\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy ograniczyć listę wyświetlanych kolumn przez polecenie `dvc exp show` poprzez zignorowanie czasu wykonania eksperymentu (flaga `--no-timestamp`), wyspecifikowanie parametrów na których nam zależy (flaga `--include-params`)\n",
    "\n",
    "```console\n",
    "$ dvc exp show --no-timestamp --include-params download_data.train_domains,evaluate_model.max_iter\n",
    "\n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
    "┃ Experiment              ┃ accuracy ┃ f1-score ┃ download_data.train_domains ┃ evaluate_model.max_iter ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
    "│ workspace               │ 0.74165  │ 0.67661  │ ['hotels']                  │ 200                     │\n",
    "│ main                    │ 0.74165  │ 0.67661  │ ['hotels']                  │ 200                     │\n",
    "│ ├── 3080e90 [exp-58a4b] │ 0.72716  │ 0.66199  │ ['hotels', 'medicine']      │ 300                     │\n",
    "│ ├── 6846c4f [exp-410e9] │ 0.57223  │ 0.51545  │ ['medicine', 'products']    │ 300                     │\n",
    "│ └── 72921d1 [exp-dd6cb] │ 0.73119  │ 0.6675   │ ['all']                     │ 300                     │\n",
    "└─────────────────────────┴──────────┴──────────┴─────────────────────────────┴─────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyświetlanie listy eksperymentów\n",
    "\n",
    "```console\n",
    "$ dvc exp list\n",
    "main:                                                                 \n",
    "        exp-58a4b\n",
    "        exp-410e9\n",
    "        exp-dd6cb\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy teraz wybrać najlepszy eksperyment, akurat w tym przypadku żaden z przeprowadzonych eksperymentów nie okazał się lepszy od konfiguracji zastosowanej na głównym branchu. Więc pozostawimy bez zmian. Ale jeżeli chcielibyśmy zaaktualizować potok na bazie któregoś z przeprowadzonych elementów możemy wykorzystać komendę `dvc exp apply` podając identyfikator eksperymentu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do usunięcia eksperymentu służy komenda `dvc remove`, możemy również usunąć stare eksperymenty za pomocą `dvc exp gc --workspace`, dodatkowo aby wyczyścić pamięc podręczną musimy również wykonać polecenie `dvc gc`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
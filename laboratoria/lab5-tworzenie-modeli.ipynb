{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "complete-circulation",
   "metadata": {},
   "source": [
    "# L5: Tworzenie modeli uczenia maszynowego"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-chile",
   "metadata": {},
   "source": [
    "## Wprowadzenie do uczenia maszynowego\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-thing",
   "metadata": {},
   "source": [
    "1. Uczenie maszynowe (ang. _machine learning_) jest obecnie najpopularniejszą dziedziną sztucznej inteligencji. \n",
    "2. Polega ono na automatycznej budowie _modelu_ poprzez ekspozycję _algorytmu_ na _dane treningowe_ w procesie zwanym _uczeniem_. \n",
    "3. Model uczenia maszynowego posiada zdolność rozpoznawania wzorców wykrytych w danych, dzięki czemu jest w stanie dokonywać _predykcji_. \n",
    "4. Celem uczenia maszynowego jest tworzenie modeli zdolnych do _generalizacji_, tj. poprawnego predykowania na danych nie użytych do treningu. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-hazard",
   "metadata": {},
   "source": [
    "W zależności od problemu który ma zostać rozwiązany, stosuje się różne metody i algorytmy, w szczególności:\n",
    "- jeśli celem jest przypisanie danym pewnej kategorycznej etykiety, mówimy o *klasyfikacji* - np. określenie czy na zdjęciu jest kot, czy pies\n",
    "- jesli celem jest umiejscowienie danych na pewnej ciągłej skali liczbowej, mówimy o *regresji* - np. prognozowanie wartości produktu\n",
    "- jeśli celem jest zgrupowanie podobnych sobie danych, mówimy o *klasteryzacji* - np. przypisanie użytkowników Twittera do grup w zależności od poruszanych tematów\n",
    "\n",
    "Klasyfikacja i regresja są przykładami _uczenia nadzorowanego_, gdzie do treningu oprócz danych wejściowych opisujących problem, musimy też posiadać _etykietę_, tj. klasę lub wartość która ma być wyjściem modelu.\n",
    "\n",
    "Klasteryzacja to przykład _uczenia nienadzorowanego_, gdzie model realizuje swoje zadanie bez dodatkowych informacji z naszej strony. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-domestic",
   "metadata": {},
   "source": [
    "![](../docs/rodzaje_uczenia.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-adrian",
   "metadata": {},
   "source": [
    "## Uczenie maszynowe przy pomocy sklearn\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-words",
   "metadata": {},
   "source": [
    "Scikit-learn (aka sklearn) jest aktualnie najpopularniejszą biblioteką w Pythonie pozwalającą kompleksowo przeprowadzać proces machine learningowy, który zazwyczaj składa się z następujących elementów:\n",
    "\n",
    "1. wczytanie zbioru danych\n",
    "2. preprocessing zbioru:\n",
    "    - transformacje cech (skalowanie, kodowanie, dyskretyzacja, embeddowanie, ekstrakcja cech itd)\n",
    "    - rozwiązanie kwestii brakujących danych\n",
    "    - rozwiązanie kwestii powtarzających się danych\n",
    "    - rozwiązanie kwestii imbalansu klas (oversampling/undersampling)\n",
    "    - augmentacja danych\n",
    "3. inżynieria cech\n",
    "4. uczenie modelu \n",
    "5. dostosowywanie (fine-tuning) parametrów\n",
    "\n",
    "Instalacja przebiega standardowo:\n",
    "\n",
    "`pip install scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-bikini",
   "metadata": {},
   "source": [
    "<br /><br /><br /><br /><br /><br /><br /><br /><br />\n",
    "## Wczytanie zbioru danych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-verification",
   "metadata": {},
   "source": [
    "Scikit-learn posiada wbudowany zestaw standardowych, benchmarkowych zbiorów danych - jak np. używany w przykładzie zbiór _wine_. Pozwala także w prosty sposób generować syntetyczne dane.\n",
    "\n",
    "Więcej informacji o dostępnych w bibliotece zbiorach danych [tutaj](https://scikit-learn.org/stable/datasets.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aboriginal-tuition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\n",
    "    \"../docs/lab4/wine_with_nulls.csv\",\n",
    ")\n",
    "\n",
    "x = dataset.drop(columns=[\"target\"])\n",
    "y = dataset[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-baseline",
   "metadata": {},
   "source": [
    "Trzymając się przyjętej konwencji matematycznej, zbiór danych wejściowych nazywamy `x`, natomiast wyjściowych - `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-jackson",
   "metadata": {},
   "source": [
    "<br /><br /><br /><br /><br /><br /><br /><br /><br />\n",
    "## Preprocessing zbioru danych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-worship",
   "metadata": {},
   "source": [
    "Odpowiednie przygotowanie danych uczących jest kluczem do sukcesu każdego przedsięwzięcia machine learningu - w myśl zasady `Garbage in, garbage out`. Przed przystąpieniem do uczenia, zazwyczaj konieczne jest wykonanie co najmniej kilku kroków wstępnego przetwarzania danych. \n",
    "\n",
    "Krok ten silnie uzależniony jest od samych danych - inaczej przygotowywać będziemy dane tekstowe, numeryczne, dźwiękowe czy obrazy. Dużą rolę gra tutaj także planowany do użycia algorytm - część z nich wymaga np. ustandaryzowanych danych.\n",
    "\n",
    "Duże znaczenie dla jakości procesu ma balans klas - w przypadku danych niezbalansowanych, część algorytmów wykazuje tendencje do preferowania klasy nadreprezentowanej, przez co popełniają błędy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-tucson",
   "metadata": {},
   "source": [
    "```{important}\n",
    "Większość algorytmów i klas zawartych w scikit-learn implementuje interfejs fit/transform - tj. przy pomocy funkcji `fit` dokonywane jest dopasowywanie algorytmów do danych uczących (uczenie/ustalanie parametrów modelu), natomiast przy pomocy funkcji `transform` dokonywane jest przekształcenie danych.\n",
    "```\n",
    "\n",
    "```{important}\n",
    "Funkcji `fit` używamy na danych treningowych, NIGDY na testowych!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-rabbit",
   "metadata": {},
   "source": [
    "W naszym komfortowym przykładzie nie ma dużej potrzeby dostosowywania danych:\n",
    "- klasy są w miarę dobrze zbalansowane\n",
    "- nie ma duplikatów\n",
    "- nie ma danych kategorycznych, poza etykietą, więc nie ma potrzeby ich kodowania"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-transportation",
   "metadata": {},
   "source": [
    "### Obsługa danych brakujących\n",
    "\n",
    "W przetwarzanym zbiorze danych występują brakujące wartości. Dane w takiej postaci nie nadają się do celów uczenia maszynowego.\n",
    "\n",
    "Istnieją dwa podejścia na rozwiązanie tej kwestii:\n",
    "- usunięcie rekordów zawierających brakujące wartości\n",
    "- uzupełnienie tych wartości"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-rwanda",
   "metadata": {},
   "source": [
    "##### Usunięcie rekordów z brakującymi danymi\n",
    "\n",
    "Jest to rozwiązanie najprostsze i potencjalnie najlepsze dla jakości klasyfikacji - usuwając \"niepewne\" rekordy, uczymy klasyfikator jedynie na pełnowartościowych danych.\n",
    "\n",
    "Minusem tego rozwiązania jest jednakże zmniejszenie się zbioru danych - polecane jest jego stosowanie jedynie w przypadku, gdy mamy wystarczającą ilość danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "together-fleece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alcohol                         True\n",
      "malic_acid                      True\n",
      "ash                             True\n",
      "alcalinity_of_ash               True\n",
      "magnesium                       True\n",
      "total_phenols                   True\n",
      "flavanoids                      True\n",
      "nonflavanoid_phenols            True\n",
      "proanthocyanins                 True\n",
      "color_intensity                 True\n",
      "hue                             True\n",
      "od280/od315_of_diluted_wines    True\n",
      "proline                         True\n",
      "dtype: bool\n",
      "(178, 13) \n",
      "\n",
      "\n",
      "alcohol                         False\n",
      "malic_acid                      False\n",
      "ash                             False\n",
      "alcalinity_of_ash               False\n",
      "magnesium                       False\n",
      "total_phenols                   False\n",
      "flavanoids                      False\n",
      "nonflavanoid_phenols            False\n",
      "proanthocyanins                 False\n",
      "color_intensity                 False\n",
      "hue                             False\n",
      "od280/od315_of_diluted_wines    False\n",
      "proline                         False\n",
      "dtype: bool\n",
      "(98, 13)\n"
     ]
    }
   ],
   "source": [
    "# sprawdźmy, czy faktycznie występują brakujące wartości\n",
    "print(x.isna().any())\n",
    "print(x.shape, \"\\n\\n\")\n",
    "\n",
    "# usuńmy je\n",
    "x_dropped = x.dropna(axis=0)\n",
    "\n",
    "# sprawdźmy ponownie\n",
    "print(x_dropped.isna().any())\n",
    "print(x_dropped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-settle",
   "metadata": {},
   "source": [
    "##### Uzupełnianie danych brakujących\n",
    "\n",
    "W przypadku gdy mamy niedostateczną ilość danych i nie możemy ich usunąć bez konsekwencji, alternatywą jest uzupełnienie danych.\n",
    "\n",
    "W tym celu należy wybrać odpowiednią wartość. Najpopularniejsze strategie to:\n",
    "- wybranie odpowiedniej statystyki (średnia/mediana) w zbiorze\n",
    "- wybranie odpowiedniej statystyki (średnia/mediana) w danej klasie\n",
    "- wybranie wartości najczęstszej w zbiorze\n",
    "- wybranie wartości najczęstszej w danej klasie\n",
    "- interpolacja wartości\n",
    "\n",
    "```\n",
    "Przydatne metody biblioteki Pandas: [fillna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna) [interpolate](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.interpolate.html#pandas.DataFrame.interpolate)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "civil-orlando",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>3.06000</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>2.76000</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.291988</td>\n",
       "      <td>3.24000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.850000</td>\n",
       "      <td>2.01976</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.36</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.69000</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.680000</td>\n",
       "      <td>0.61000</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>0.69000</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>0.68000</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.36</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.050000</td>\n",
       "      <td>0.76000</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0       2.800000   \n",
       "1      13.20        1.78  2.14               11.2      100.0       2.650000   \n",
       "2      13.16        2.36  2.67               18.6      101.0       2.291988   \n",
       "3      14.37        1.95  2.50               16.8      113.0       3.850000   \n",
       "4      13.24        2.59  2.36               21.0      118.0       2.800000   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0       1.680000   \n",
       "174    13.40        3.91  2.48               23.0      102.0       1.800000   \n",
       "175    13.27        4.28  2.26               20.0      120.0       1.590000   \n",
       "176    13.17        2.59  2.37               20.0      120.0       1.650000   \n",
       "177    14.13        4.10  2.36               24.5       96.0       2.050000   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0       3.06000                  0.28             2.29             5.64  1.04   \n",
       "1       2.76000                  0.26             1.28             4.38  1.05   \n",
       "2       3.24000                  0.30             2.81             5.68  1.03   \n",
       "3       2.01976                  0.24             2.18             7.80  0.86   \n",
       "4       2.69000                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173     0.61000                  0.52             1.06             7.70  0.64   \n",
       "174     0.75000                  0.43             1.41             7.30  0.70   \n",
       "175     0.69000                  0.43             1.35            10.20  0.59   \n",
       "176     0.68000                  0.53             1.46             9.30  0.60   \n",
       "177     0.76000                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "0                            3.92   1065.0  \n",
       "1                            3.40   1050.0  \n",
       "2                            3.17   1185.0  \n",
       "3                            3.45   1480.0  \n",
       "4                            2.93    735.0  \n",
       "..                            ...      ...  \n",
       "173                          1.74    740.0  \n",
       "174                          1.56    750.0  \n",
       "175                          1.56    835.0  \n",
       "176                          1.62    840.0  \n",
       "177                          1.60    560.0  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uzupełnimy wartości średnimi w zbiorze\n",
    "\n",
    "x = x.fillna(value=x.mean())\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-maldives",
   "metadata": {},
   "source": [
    "### Transformacje cech\n",
    "\n",
    "#### Skalowanie wartości cech\n",
    "\n",
    "Część algorytmów jest wrażliwa na zróżnicowanie wartości poszczególnych cech. Są to w szczególności:\n",
    "* algorytmy bazujące na gradientach - np. regresja logistyczna, sieci neuronowe\n",
    "* algorytmy bazujące na odległościach - np. kNN, SVM, k-means\n",
    "\n",
    "Niektóre algorytmy doskonale radzą sobie nawet z dużymi dysproporcjami rozkładami wartości poszczególnych cech - w szczególności np. drzewa decyzyjne i lasy losowe.\n",
    "\n",
    "Istnieją dwie standardowe metody skalowania cech:\n",
    "* standaryzacja - przekształcenie wartości posiadających rozkład zbliżony do normalnego do takiego posiadającego średnią w zerze i odchylenie standardowe równe 1\n",
    "* normalizacja - przekształcenie wartości o nieznanym rozkładzie do takiego, który ma maksymalną wartości równą 1. Jest wrażliwa na outliery!\n",
    "\n",
    "![](../docs/lab5/feature_scaling.png)\n",
    "\n",
    "\n",
    "\n",
    "##### Standaryzacja cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "numerical-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "difficult-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zdefiniujmy funkcję wyświetlajacą statystyki średniej i odchylenia standardowego\n",
    "def print_dataset_stats(x):\n",
    "    print(\"Średnia cech:\\n\", x.mean(axis=0))\n",
    "    print()\n",
    "    print(\"Odchylenie standardowe cech:\\n\", x.std(axis=0))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pleasant-account",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przed standaryzacją\n",
      "Średnia cech:\n",
      " alcohol                          13.009357\n",
      "malic_acid                        2.318059\n",
      "ash                               2.360000\n",
      "alcalinity_of_ash                19.404790\n",
      "magnesium                       100.088757\n",
      "total_phenols                     2.291988\n",
      "flavanoids                        2.019760\n",
      "nonflavanoid_phenols              0.365614\n",
      "proanthocyanins                   1.583295\n",
      "color_intensity                   5.009529\n",
      "hue                               0.959920\n",
      "od280/od315_of_diluted_wines      2.615176\n",
      "proline                         756.209302\n",
      "dtype: float64\n",
      "\n",
      "Odchylenie standardowe cech:\n",
      " alcohol                           0.803573\n",
      "malic_acid                        1.083068\n",
      "ash                               0.268717\n",
      "alcalinity_of_ash                 3.223883\n",
      "magnesium                        14.117679\n",
      "total_phenols                     0.613800\n",
      "flavanoids                        0.974356\n",
      "nonflavanoid_phenols              0.120615\n",
      "proanthocyanins                   0.564260\n",
      "color_intensity                   2.240211\n",
      "hue                               0.226580\n",
      "od280/od315_of_diluted_wines      0.690702\n",
      "proline                         310.213727\n",
      "dtype: float64\n",
      "\n",
      "Po standaryzacji\n",
      "Średnia cech:\n",
      " [-2.91402358e-15 -1.59672525e-16 -1.26615322e-15 -3.99181312e-16\n",
      "  1.75639777e-15  1.99590656e-16  3.99181312e-17 -2.79426919e-16\n",
      " -5.98771968e-17  2.89406451e-16 -4.79017575e-16  4.79017575e-16\n",
      " -1.99590656e-16]\n",
      "\n",
      "Odchylenie standardowe cech:\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(x)\n",
    "\n",
    "print(\"Przed standaryzacją\")\n",
    "print_dataset_stats(x)\n",
    "x = scaler.transform(x)\n",
    "print(\"Po standaryzacji\")\n",
    "print_dataset_stats(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-decision",
   "metadata": {},
   "source": [
    "```{seealso}\n",
    "Do normalizacji służy analogiczny moduł sklearn - `MinMaxScaler`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-spyware",
   "metadata": {},
   "source": [
    "### Kodowanie cech kategorycznych\n",
    "\n",
    "Kodowanie cech kategorycznych ma na celu przekształcenie ich do formy numerycznej, by umożliwić ich obsługę przez algorytmy ML. Nie wszystkie algorytmy wymagają kodowania (np. drzewa)\n",
    "\n",
    "#### Label encoding\n",
    "Polega na przypisywaniu wartościom kategorycznym kolejnych wartości liczbowych, np:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "iraqi-ridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit_transform([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-absence",
   "metadata": {},
   "source": [
    "```{important}\n",
    "Wartości są przypisywane w kolejności alfabetycznej, stąd algorytm może zostać wprowadzony w błąd, jesli dane nie wykazują takiej zależności!\n",
    "```\n",
    "\n",
    "#### One-hot encoding\n",
    "Alternatywą jest zakodować wartości jako wektor, gdzie każda pozycja odpowiada jednej z wartości:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "searching-economics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit_transform([[\"paris\"], [\"paris\"], [\"tokyo\"], [\"amsterdam\"]]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-nation",
   "metadata": {},
   "source": [
    "### Wektoryzacja tekstu\n",
    "\n",
    "Podstawową metodą zamiany tekstu na wektor liczbowy jest metoda Bag-of-Words. To rozbudowa metody one-hot encoding dla danych tekstowych (w technicznej implementacji używane są rzadkie macierze).\n",
    "\n",
    "Plusem jest jej prostota, minusem całkowity brak uwzględnienia zależności w tekście"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "correct-subcommittee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1073, 18217)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups = fetch_20newsgroups(\n",
    "    subset=\"train\",\n",
    "    categories=[\"alt.atheism\", \"sci.space\"],\n",
    "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
    ")\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "x_train_counts = count_vect.fit_transform(newsgroups[\"data\"])\n",
    "x_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accredited-sleep",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15360"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_.get(\"space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "considerable-grocery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]]\n",
      "(1, 18217)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "xxx = count_vect.transform(\n",
    "    [\"god saved a space shuttle from atheism revolution\"]\n",
    ").toarray()\n",
    "print(xxx)\n",
    "print(xxx.shape)\n",
    "print(xxx.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-estonia",
   "metadata": {},
   "source": [
    "<br /><br /><br /><br /><br /><br /><br /><br /><br />\n",
    "\n",
    "\n",
    "## Inżynieria cech (ang. feature engineering)\n",
    "\n",
    "Inżynieria cech jest procesem wykorzystywania wiedzy domenowej na temat danych do tworzenia funkcji umożliwiających działanie algorytmów uczenia maszynowego. Poprawne przygotowanie cech bardzo zwiększa moc predykcyjną algorytmów.\n",
    "\n",
    "Przykładowo, mając dane nt. pewnej populacji, cecha wzrostu danego człowieka może nie mieć mocy predykcyjnej lub jest ona ciężka do użycia przez prostsze algorytmy. Niemniej przekształcenie jej do informacji o tym czy dany człowiek jest wyższy/niższy od średniego wzrostu w danej populacji może pomóc.\n",
    "\n",
    "\n",
    "### Selekcja cech / redukcja wymiarowości\n",
    "\n",
    "W wielu zbiorach danych występują cechy, które nie są informacyjne. Usunięcie takich cech często pozwala na poprawę jakości predykcji. Ograniczenie ilości cech ułatwia także technicznie proces uczenia - algorytm musi przetworzyc mniej danych, wiec dzieje się to szybciej. Istnieje wiele metod selekcji cech, np. bazujacych na testach statystycznych. Ich ogólna idea polega na ocenieniu cech wg. zadanej miary jakości, a następnie wyboru najbardziej wartościowych. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "empty-semester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# usunięcie cech z niską wariancją\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "x = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]\n",
    "sel = VarianceThreshold(threshold=(0.8 * (1 - 0.8)))\n",
    "sel.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "heated-detection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n",
      "(178, 6)\n"
     ]
    }
   ],
   "source": [
    "# usunięcie cech na podstawie testu statystycznego\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "x, y = load_wine(return_X_y=True)\n",
    "print(x.shape)\n",
    "x_new = SelectKBest(chi2, k=6).fit_transform(x, y)\n",
    "print(x_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-mayor",
   "metadata": {},
   "source": [
    "\n",
    "Alternatywnie stosuje się metody redukcji wymiarowości. W przeciwieństwie do selekcji cech, która jedynie wybiera spośród istniejących już danych pewien ich podzbiór, algorytmy redukcji wymiarowości przekształcają dane, tworząc nowe, bardziej informacyjne cechy. Najpopularniejszą metodą redukcji wymiarowości jest `PCA`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-usage",
   "metadata": {},
   "source": [
    "<br /><br /><br /><br /><br /><br /><br /><br /><br />\n",
    "## Uczenie modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-friendship",
   "metadata": {},
   "source": [
    "Mając odpowiednio przygotowane dane, możemy przystąpić do procesu uczenia. Pierwszym krokiem będzie podział zbioru na część treningową (na której nauczymy model) oraz testową (na której przetestujemy jego jakość). Taki podział pozwala zmierzyć zdolność modelu do generalizacji - sprawdzamy jakość na danych, które nie były użyte do nauki, których \"model wcześniej nie widział\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "professional-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=666\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "effective-wound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (142, 13)\n",
      "x_test:  (36, 13)\n",
      "y_train:  (142,)\n",
      "y_test:  (36,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train: \", x_train.shape)\n",
    "print(\"x_test: \", x_test.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-thinking",
   "metadata": {},
   "source": [
    "Finalnie jesteśmy gotowi stworzyć klasyfikator. Dla przykładu użyjemy algorytmu SVM. Przykłady innych modeli można znaleźć [tutaj](https://scikit-learn.org/stable/supervised_learning.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "distinguished-designation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC()\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-violin",
   "metadata": {},
   "source": [
    "Możemy go teraz użyć w celu predykcji nowych wartości:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "prostate-subject",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(x_test[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-radius",
   "metadata": {},
   "source": [
    "```{important}\n",
    "Istnieje wiele modeli uczenia maszynowego. Wybór odpowiedniego zależy od problemu który rozwiązujemy, danych które posiadamy, pożądanemu rezultatowi i warunkom działania (np. pożądana szybkość uczenia i inferencji).\n",
    "\n",
    "Do najpopularniejszych modeli nadzorowanych należą - drzewa decyzyjne (i lasy losowe), kNN, SVM, Naive Bayes, sieci neuronowe.\n",
    "\n",
    "Niestety, dokładne wprowadzenie w fascynującą dziedzinę modelu uczenia maszynowego leży poza zakresem tego laboratorium.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-programming",
   "metadata": {},
   "source": [
    "### Potoki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-leeds",
   "metadata": {},
   "source": [
    "W przypadku bardziej rozbudowanego preprocessingu, niezwykle przydatna staje się możliwość łączenia wszystkich użytych mechanizmów w jeden potok:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "actual-elephant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;variancethreshold&#x27;,\n",
       "                 VarianceThreshold(threshold=0.15999999999999998)),\n",
       "                (&#x27;svc&#x27;, SVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;variancethreshold&#x27;,\n",
       "                 VarianceThreshold(threshold=0.15999999999999998)),\n",
       "                (&#x27;svc&#x27;, SVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VarianceThreshold</label><div class=\"sk-toggleable__content\"><pre>VarianceThreshold(threshold=0.15999999999999998)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('variancethreshold',\n",
       "                 VarianceThreshold(threshold=0.15999999999999998)),\n",
       "                ('svc', SVC())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "x, y = load_wine(return_X_y=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=13\n",
    ")\n",
    "\n",
    "pipeline_classifier = make_pipeline(\n",
    "    StandardScaler(), VarianceThreshold(threshold=(0.8 * (1 - 0.8))), SVC()\n",
    ")\n",
    "\n",
    "pipeline_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "accepted-dancing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_classifier.predict(x_test[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-jefferson",
   "metadata": {},
   "source": [
    "### Analiza jakości modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-medium",
   "metadata": {},
   "source": [
    "Na tym etapie posiadamy zbiór danych podzielony na część treningową i testową, oraz klasyfikator nauczony na częsci treningowej. Jak sprawdzić, jak dobrze jest on nauczony?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-mentor",
   "metadata": {},
   "source": [
    "Do określenia jakości modelu służy szereg metryk, różnych w zależności od problemu. \n",
    "\n",
    "W zadaniu klasyfikacji, standardowo używa się następujących miar wywodzących się z klasyfikacji binarnej:\n",
    "- accuracy, oznaczająca procent poprawnie oznaczonych przykładów\n",
    "- F1 - będąca średnią miar `precision` i `recall`, mierzących skłonności modelu do niepopełniania błędów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "official-paste",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9722222222222222\n",
      "F1:  0.9696394686907022\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predicted = pipeline_classifier.predict(x_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_predicted))\n",
    "print(\"F1: \", f1_score(y_test, y_predicted, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-pipeline",
   "metadata": {},
   "source": [
    "Dokładniejsze informacje o jakości klasyfikacji możemy uzyskac np. przy pomocy metody `classification_report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "documentary-consciousness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       0.94      1.00      0.97        15\n",
      "           2       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.96      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-health",
   "metadata": {},
   "source": [
    "W przypadku zadania regresji, standardowo używaną miarą jest błąd średniokwadratowy (`ang. mean square error`). Więcej informacji o różnych rodzajach metryk jakości modelu - [tutaj](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-plymouth",
   "metadata": {},
   "source": [
    "### Walidacja krzyżowa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-empty",
   "metadata": {},
   "source": [
    "Powyżej nauczyliśmy model klasyfikować - i to z bardzo dobrą jakością! \n",
    "\n",
    "Jednakże, nauczyliśmy nasz model na pewnym podzbiorze danych i przetestowaliśmy na innym. Nie mamy pewności, czy model sam w sobie wykazuje się dobrą jakością, czy to akurat ten specyficzny wybór podzbiorów danych daje tak dobre wyniki.\n",
    "\n",
    "Z pomocą przychodzi tutaj `walidacja krzyżowa | sprawdzanie krzyżowe` `(ang. cross-validation)`. Jest to procedura polegająca na kilkukrotnym uruchomieniu procedury uczenia modelu, za każdym razem na innym podzbiorze danych. Uśredniony wynik takich kilku modeli pozwala z większą dokładnością wyrokować o jakości samego modelu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cosmetic-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "x, y = load_wine(return_X_y=True)\n",
    "cv_results = cross_validate(pipeline_classifier, x, y, scoring=\"f1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "turkish-softball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.983504493924021"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results[\"test_score\"].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "przetwarzanie-danych-i-odkrywanie-wiedzy",
   "language": "python",
   "name": "przetwarzanie-danych-i-odkrywanie-wiedzy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dynamic-investigator",
   "metadata": {},
   "source": [
    "![](../docs/banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-circulation",
   "metadata": {},
   "source": [
    "# Laboratorium 3: Tworzenie modeli uczenia maszynowego"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-check",
   "metadata": {},
   "source": [
    "## Efekty kształcenia laboratorium\n",
    "---\n",
    "\n",
    "Podczas niniejszych zajęć:\n",
    "\n",
    "+ poznasz podstawowe pojęcia z zakresu uczenia maszynowego\n",
    "+ dowiesz się jak przeprowadzić analizę statystyczną zbioru danych i na co zwrócić uwagę\n",
    "+ poznasz i przeprowadzisz cały proces uczenia masznowego - od wczytania zbioru, poprzez jego transformacje, uczenie, aż po walidację krzyżową i dostrajanie parametrów modelu\n",
    "+ poznasz podstawowe mechanizmy sprawdzania jakości modelu uczenia maszynowego"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-chile",
   "metadata": {},
   "source": [
    "## Wprowadzenie\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-thing",
   "metadata": {},
   "source": [
    "1. Uczenie maszynowe (ang. _machine learning_) jest obecnie najpopularniejszą dziedziną sztucznej inteligencji. \n",
    "2. Polega ono na automatycznej budowie _modelu_ poprzez ekspozycję _algorytmu_ na _dane treningowe_ w procesie zwanym _uczeniem_. \n",
    "3. Model uczenia maszynowego posiada zdolność rozpoznawania wzorców wykrytych w danych, dzięki czemu jest w stanie dokonywać _predykcji_. \n",
    "4. Celem uczenia maszynowego jest tworzenie modeli zdolnych do _generalizacji_, tj. poprawnego predykowania na danych nie użytych do treningu. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-hazard",
   "metadata": {},
   "source": [
    "W zależności od problemu który ma zostać rozwiązany, stosuje się różne metody i algorytmy, w szczególności:\n",
    "- jeśli celem jest przypisanie danym pewnej kategorycznej etykiety, mówimy o *klasyfikacji* - np. określenie czy na zdjęciu jest kot, czy pies\n",
    "- jesli celem jest umiejscowienie danych na pewnej ciągłej skali liczbowej, mówimy o *regresji* - np. prognozowanie wartości produktu\n",
    "- jeśli celem jest zgrupowanie podobnych sobie danych, mówimy o *klasteryzacji* - np. przypisanie użytkowników Twittera do grup w zależności od poruszanych tematów\n",
    "\n",
    "Klasyfikacja i regresja są przykładami _uczenia nadzorowanego_, gdzie do treningu oprócz danych wejściowych opisujących problem, musimy też posiadać _etykietę_, tj. klasę lub wartość która ma być wyjściem modelu.\n",
    "\n",
    "Klasteryzacja to przykład _uczenia nienadzorowanego_, gdzie model realizuje swoje zadanie bez dodatkowych informacji z naszej strony. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-domestic",
   "metadata": {},
   "source": [
    "![](../docs/rodzaje_uczenia.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-millennium",
   "metadata": {},
   "source": [
    "## Analiza statystyczna zbioru treningowego\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-apparel",
   "metadata": {},
   "source": [
    "Przed rozpoczęciem rozwiązywania problemu przy użyciu metod uczenia maszynowego, w szczególności przed rozpoczęciem budowania modelu, konieczne jest sprawdzenie, z jakimi danymi przyszło się nam mierzyć. \n",
    "\n",
    "Wśród podstawowych kwestii, które powinniśmy sprawdzić, są:\n",
    "- ile mamy cech?\n",
    "- które spośród nich to cechy kategoryczne, a które numeryczne?\n",
    "- jakie wartości przyjmują poszczególne cechy?\n",
    "- czy wśród danych są brakujące wartości?\n",
    "- czy istnieje i jak wygląda etykieta? (w szczególności - czy mierzymy się z zadaniem klasyfikacji, regresji czy klasteryzacji?) \n",
    "- czy dane są zbalansowane względem danej wyjściowej?\n",
    "\n",
    "Dla małych i prostych zbiorów do nauki (tzw. _toy tasks_), zazwyczaj wystarczające jest ręczne przejrzenie pliku z danymi, by potrafić odpowiedzieć na w/w pytania. Niemniej przy bardziej ambitnych zadaniach, z pomocą przychodzą narzędzia automatyzujące pracę. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-knight",
   "metadata": {},
   "source": [
    "### Przykładowy zbiór danych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-duplicate",
   "metadata": {},
   "source": [
    "Przeanalizujmy klasyczny zbiór danych dotyczący wina (opublikowany przez `Forina, M. et al, PARVUS - An Extendible Package for Data Exploration, Classification and Correlation. Institute of Pharmaceutical and Food Analysis and Technologies, Via Brigata Salerno, 16147 Genoa, Italy`, więcej informacji [tutaj](https://archive.ics.uci.edu/ml/datasets/wine))\n",
    "\n",
    "Zbiór zawiera właściwości fizykochemiczne różnych próbek wina pobranych z jednego z regionów słonecznej Italii, jednakże pochodzących od trzech różnych plantatorów. Założeniem problemu jest określenie, który z nich jest wytwórcą danej próbki."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-hands",
   "metadata": {},
   "source": [
    "Zacznijmy od wczytania zbioru:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "inappropriate-sarah",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0       0  \n",
       "1                          3.40   1050.0       0  \n",
       "2                          3.17   1185.0       0  \n",
       "3                          3.45   1480.0       0  \n",
       "4                          2.93    735.0       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "dataset, y = load_wine(as_frame=True, return_X_y=True)\n",
    "dataset['target'] = y\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-impossible",
   "metadata": {},
   "source": [
    "Na pierwszy rzut oka możemy stwierdzić, że wszystkie kolumny są numeryczne, ale ich wartości różnią się dość znacząco. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-providence",
   "metadata": {},
   "source": [
    "Podstawowe informacje o statystykach zbioru danych możemy uzyskać przy wbudowanej w Pandas metodzie `describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "blond-mobile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "      <td>0.938202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "      <td>0.775035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
       "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
       "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
       "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
       "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
       "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
       "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
       "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
       "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
       "\n",
       "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "count     178.000000  178.000000            178.000000       178.000000   \n",
       "mean        2.295112    2.029270              0.361854         1.590899   \n",
       "std         0.625851    0.998859              0.124453         0.572359   \n",
       "min         0.980000    0.340000              0.130000         0.410000   \n",
       "25%         1.742500    1.205000              0.270000         1.250000   \n",
       "50%         2.355000    2.135000              0.340000         1.555000   \n",
       "75%         2.800000    2.875000              0.437500         1.950000   \n",
       "max         3.880000    5.080000              0.660000         3.580000   \n",
       "\n",
       "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \\\n",
       "count       178.000000  178.000000                    178.000000   178.000000   \n",
       "mean          5.058090    0.957449                      2.611685   746.893258   \n",
       "std           2.318286    0.228572                      0.709990   314.907474   \n",
       "min           1.280000    0.480000                      1.270000   278.000000   \n",
       "25%           3.220000    0.782500                      1.937500   500.500000   \n",
       "50%           4.690000    0.965000                      2.780000   673.500000   \n",
       "75%           6.200000    1.120000                      3.170000   985.000000   \n",
       "max          13.000000    1.710000                      4.000000  1680.000000   \n",
       "\n",
       "           target  \n",
       "count  178.000000  \n",
       "mean     0.938202  \n",
       "std      0.775035  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      1.000000  \n",
       "75%      2.000000  \n",
       "max      2.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-cornell",
   "metadata": {},
   "source": [
    "Jednakże w celu dokładniejszej analizy zbioru, posłużymy się biblioteką Pandas Profiling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-essence",
   "metadata": {},
   "source": [
    "### Pandas Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-pressure",
   "metadata": {},
   "source": [
    "Jest to biblioteka automatycznie analizująca zbiór danych i generujaca interaktywny raport. Alternatywnie, raport można zapisać w formacie `.html`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-morris",
   "metadata": {},
   "source": [
    "Na dzień tworzenia tego zadania (2021.02.06) wersja 2.10 biblioteki zawiera błąd nie pozwalający generować raportu w środowisku Jupyter. Posłużymy się więc wersją 2.9, która działa poprawnie.\n",
    "\n",
    "Upewnijmy się, że jest ona poprawnie zainstalowana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "unable-badge",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas-profiling==2.9.0 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (2.9.0)\n",
      "Requirement already satisfied: matplotlib>=3.2.0 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from pandas-profiling==2.9.0) (3.3.4)\n",
      "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from pandas-profiling==2.9.0) (1.2.1)\n",
      "Requirement already satisfied: missingno>=0.4.2 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from pandas-profiling==2.9.0) (0.4.2)\n",
      "Requirement already satisfied: phik>=0.9.10 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from pandas-profiling==2.9.0) (0.11.0)\n",
      "Requirement already satisfied: htmlmin>=0.1.12 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from pandas-profiling==2.9.0) (0.1.12)\n",
      "Requirement already satisfied: tqdm>=4.43.0 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from pandas-profiling==2.9.0) (4.56.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from pandas-profiling==2.9.0) (1.6.0)\n",
      "Requirement already satisfied: ipywidgets>=7.5.1 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from pandas-profiling==2.9.0) (7.6.3)\n",
      "Requirement already satisfied: attrs>=19.3.0 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from pandas-profiling==2.9.0) (20.3.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from pandas-profiling==2.9.0) (2.25.1)\n",
      "Requirement already satisfied: seaborn>=0.10.1 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from pandas-profiling==2.9.0) (0.11.1)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from pandas-profiling==2.9.0) (2.11.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from pandas-profiling==2.9.0) (1.20.0)\n",
      "Requirement already satisfied: visions[type_image_path]==0.5.0 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from pandas-profiling==2.9.0) (0.5.0)\n",
      "Requirement already satisfied: tangled-up-in-unicode>=0.0.6 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from pandas-profiling==2.9.0) (0.0.6)\n",
      "Requirement already satisfied: joblib in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from pandas-profiling==2.9.0) (1.0.0)\n",
      "Requirement already satisfied: confuse>=1.0.0 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from pandas-profiling==2.9.0) (1.4.0)\n",
      "Requirement already satisfied: networkx>=2.4 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from visions[type_image_path]==0.5.0->pandas-profiling==2.9.0) (2.5)\n",
      "Requirement already satisfied: Pillow in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from visions[type_image_path]==0.5.0->pandas-profiling==2.9.0) (8.1.0)\n",
      "Requirement already satisfied: imagehash in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from visions[type_image_path]==0.5.0->pandas-profiling==2.9.0) (4.2.0)\n",
      "Requirement already satisfied: pyyaml in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from confuse>=1.0.0->pandas-profiling==2.9.0) (5.4.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from ipywidgets>=7.5.1->pandas-profiling==2.9.0) (5.0.5)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from ipywidgets>=7.5.1->pandas-profiling==2.9.0) (1.0.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from ipywidgets>=7.5.1->pandas-profiling==2.9.0) (5.1.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from ipywidgets>=7.5.1->pandas-profiling==2.9.0) (3.5.1)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from ipywidgets>=7.5.1->pandas-profiling==2.9.0) (7.20.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from ipywidgets>=7.5.1->pandas-profiling==2.9.0) (5.4.3)\n",
      "Requirement already satisfied: appnope in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (0.1.2)\n",
      "Requirement already satisfied: tornado>=4.2 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (6.1)\n",
      "Requirement already satisfied: jupyter-client in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (6.1.11)\n",
      "Requirement already satisfied: backcall in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (0.18.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (4.8.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (49.2.1)\n",
      "Requirement already satisfied: pygments in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (2.7.4)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (3.0.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (0.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from jinja2>=2.11.1->pandas-profiling==2.9.0) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from matplotlib>=3.2.0->pandas-profiling==2.9.0) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from matplotlib>=3.2.0->pandas-profiling==2.9.0) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from matplotlib>=3.2.0->pandas-profiling==2.9.0) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from matplotlib>=3.2.0->pandas-profiling==2.9.0) (1.3.1)\n",
      "Requirement already satisfied: six in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=3.2.0->pandas-profiling==2.9.0) (1.15.0)\n",
      "Requirement already satisfied: ipython-genutils in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (3.2.0)\n",
      "Requirement already satisfied: jupyter-core in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (4.7.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (0.17.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas-profiling==2.9.0) (2021.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (0.7.0)\n",
      "Requirement already satisfied: numba>=0.38.1 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from phik>=0.9.10->pandas-profiling==2.9.0) (0.52.0)\n",
      "Requirement already satisfied: llvmlite<0.36,>=0.35.0 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from numba>=0.38.1->phik>=0.9.10->pandas-profiling==2.9.0) (0.35.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wcwidth in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (0.2.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from requests>=2.23.0->pandas-profiling==2.9.0) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from requests>=2.23.0->pandas-profiling==2.9.0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from requests>=2.23.0->pandas-profiling==2.9.0) (1.26.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from requests>=2.23.0->pandas-profiling==2.9.0) (2.10)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (6.2.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (1.5.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (22.0.2)\n",
      "Requirement already satisfied: nbconvert in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (5.6.1)\n",
      "Requirement already satisfied: argon2-cffi in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (20.1.0)\n",
      "Requirement already satisfied: prometheus-client in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (0.9.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (0.9.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (1.14.4)\n",
      "Requirement already satisfied: pycparser in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (2.20)\n",
      "Requirement already satisfied: PyWavelets in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from imagehash->visions[type_image_path]==0.5.0->pandas-profiling==2.9.0) (1.1.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (0.8.4)\n",
      "Requirement already satisfied: testpath in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (0.4.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (1.4.3)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (0.3)\n",
      "Requirement already satisfied: bleach in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (3.3.0)\n",
      "Requirement already satisfied: defusedxml in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (0.6.0)\n",
      "Requirement already satisfied: packaging in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (20.9)\n",
      "Requirement already satisfied: webencodings in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas-profiling==2.9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-pasta",
   "metadata": {},
   "source": [
    "Użycie biblioteki jest niezwykle proste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "informative-october",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d84f0e5143466690963c2ff4a8e289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2508e2565d843c3b368316c203769c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render widgets:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651b34a55a514dc6a807af38aa9897ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "profile = ProfileReport(dataset)\n",
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-magnitude",
   "metadata": {},
   "source": [
    "Z raportu dowiadujemy się między innymi:\n",
    "- mamy 13 kolumn numerycznych (dane wejściowe), jedną kategoryczną (etykieta) - będziemy więc zajmować się klasyfikacją\n",
    "- klasy są całkiem nieźle zbalansowane (39%, 33%, 27%)\n",
    "- nie mamy brakujących wartości ani duplikatów\n",
    "- możemy dokładnie przeanalizować statystyki poszczególnych cech, ich histogramy oraz wykresy zależności pomiędzy nimi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-adrian",
   "metadata": {},
   "source": [
    "## Uczenie maszynowe przy pomocy sklearn\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-words",
   "metadata": {},
   "source": [
    "Scikit-learn (aka sklearn) jest aktualnie najpopularniejszą biblioteką w Pythonie pozwalającą kompleksowo przeprowadzać proces machine learningowy, który zazwyczaj składa się z następujących elementów:\n",
    "\n",
    "1. wczytanie zbioru danych\n",
    "2. preprocessing zbioru:\n",
    "    - transformacje cech (normalizacja, skalowanie, kodowanie, dyskretyzacja, embeddowanie, ekstrakcja cech itd)\n",
    "    - rozwiązanie kwestii brakujących i powtarzających się danych\n",
    "    - rozwiązanie kwestii imbalansu klas (oversampling/undersampling)\n",
    "    - augmentacja danych\n",
    "3. selekcja cech/redukcja wymiarowości\n",
    "4. uczenie modelu \n",
    "5. dostosowywanie (fine-tuning) parametrów\n",
    "\n",
    "Jednakże zanim pokrótce zapoznamy się z tymi metodami, upewnijmy się, że scikit-learn jest poprawnie zainstalowany:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "pleasant-script",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/xaru/work/pdiow/lib/python3.8/site-packages (0.24.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from scikit-learn) (1.6.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from scikit-learn) (1.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/xaru/work/pdiow/lib/python3.8/site-packages (from scikit-learn) (1.20.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-bikini",
   "metadata": {},
   "source": [
    "### Wczytanie zbioru danych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-verification",
   "metadata": {},
   "source": [
    "Scikit-learn posiada wbudowany zestaw standardowych, benchmarkowych zbiorów danych - jak np. używany w przykładzie zbiór _wine_. Pozwala także w prosty sposób generować syntetyczne dane.\n",
    "\n",
    "Więcej informacji o dostępnych w bibliotece zbiorach danych [tutaj](https://scikit-learn.org/stable/datasets.html)\n",
    "\n",
    "W przypadku rzeczywistych problemów i własnych datasetów - będziemy jednak używać biblioteki Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aboriginal-tuition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  \n",
       "2                          3.17   1185.0  \n",
       "3                          3.45   1480.0  \n",
       "4                          2.93    735.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# użyty już przykład wczytania datasetu wine, dla przypomnienia\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "X, y = load_wine(as_frame=True, return_X_y=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-baseline",
   "metadata": {},
   "source": [
    "Trzymając się przyjętej konwencji matematycznej, zbiór danych wejściowych nazywamy `X`, natomiast wyjściowych - `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-jackson",
   "metadata": {},
   "source": [
    "### Preprocessing zbioru danych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-worship",
   "metadata": {},
   "source": [
    "Odpowiednie przygotowanie danych uczących jest kluczem do sukcesu każdego przedsięwzięcia machine learningu - w myśl zasady `Garbage in, garbage out`. Przed przystąpieniem do uczenia, zazwyczaj konieczne jest wykonanie co najmniej kilku kroków wstępnego przetwarzania danych. \n",
    "\n",
    "Krok ten silnie uzależniony jest od samych danych - inaczej przygotowywać będziemy dane tekstowe, numeryczne, dźwiękowe czy obrazy. Dużą rolę gra tutaj także planowany do użycia algorytm - część z nich wymaga np. ustandaryzowanych danych (tj. pochodzących z rozkładu zbliżonego do normalnego, posiadających średnia w 0 i odchylenie standardowe równe 1). \n",
    "\n",
    "Duże znaczenie dla jakości procesu ma balans klas - w przypadku danych niezbalansowanych, część algorytmów wykazuje tendencje do preferowania klasy nadreprezentowanej, przez co popełniają błędy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-wallet",
   "metadata": {},
   "source": [
    "Ponadto w wielu zbiorach danych występują cechy, które nie są informacyjne. Usunięcie takich cech często pozwala na poprawę jakości predykcji. Ograniczenie ilości cech ułatwia także technicznie proces uczenia - algorytm musi przetworzyc mniej danych, wiec dzieje się to szybciej. Istnieje wiele metod selekcji cech, np. bazujacych na testach statystycznych. Ich ogólna idea polega na ocenieniu cech wg. zadanej miary jakości, a następnie wyboru najbardziej wartościowych. \n",
    "\n",
    "Alternatywnie stosuje się metody redukcji wymiarowości. W przeciwieństwie do selekcji cech, która jedynie wybiera spośród istniejących już danych pewien ich podzbiór, algorytmy redukcji wymiarowości przekształcają dane, tworząc nowe, bardziej informacyjne cechy. Najpopularniejszą metodą redukcji wymiarowości jest `PCA`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-translator",
   "metadata": {},
   "source": [
    "``` {hint}\n",
    "Preprocessingowi poświęcone zostało Laboratorium 4, gdzie w/w mechanizmy zostaną omówione dokładniej. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-rabbit",
   "metadata": {},
   "source": [
    "W naszym komfortowym przykładzie nie ma dużej potrzeby dostosowywania danych:\n",
    "- klasy są w miarę dobrze zbalansowane\n",
    "- nie ma wartości brakujących\n",
    "- nie ma duplikatów\n",
    "- nie ma danych kategorycznych, poza etykietą, więc nie ma potrzeby ich kodowania\n",
    "\n",
    "Operujemy natomiast na danych numerycznych, które mają skrajnie różne wartości pomiędzy cechami, poddamy je więc standaryzacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "numerical-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# najpierw przekształćmy dataset do formatu numpy, akceptowalnego przez scikit-learn\n",
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "difficult-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zdefiniujmy funkcję wyświetlajacą statystyki średniej i odchylenia standardowego\n",
    "def print_dataset_stats(X):\n",
    "    print('Średnia cech:\\n', X.mean(axis=0))\n",
    "    print()\n",
    "    print('Odchylenie standardowe cech:\\n', X.std(axis=0))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-migration",
   "metadata": {},
   "source": [
    "```{important}\n",
    "Większość algorytmów i klas zawartych w scikit-learn implementuje interfejs fit/transform - tj. przy pomocy funkcji `fit` dokonywane jest dopasowywanie algorytmów do danych uczących (uczenie/ustalanie parametrów modelu), natomiast przy pomocy funkcji `transform` dokonywane jest przekształcenie danych.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "pleasant-account",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przed standaryzacją\n",
      "Średnia cech:\n",
      " [1.30006180e+01 2.33634831e+00 2.36651685e+00 1.94949438e+01\n",
      " 9.97415730e+01 2.29511236e+00 2.02926966e+00 3.61853933e-01\n",
      " 1.59089888e+00 5.05808988e+00 9.57449438e-01 2.61168539e+00\n",
      " 7.46893258e+02]\n",
      "\n",
      "Odchylenie standardowe cech:\n",
      " [8.09542915e-01 1.11400363e+00 2.73572294e-01 3.33016976e+00\n",
      " 1.42423077e+01 6.24090564e-01 9.96048950e-01 1.24103260e-01\n",
      " 5.70748849e-01 2.31176466e+00 2.27928607e-01 7.07993265e-01\n",
      " 3.14021657e+02]\n",
      "\n",
      "Po standaryzacji\n",
      "Średnia cech:\n",
      " [-8.38280756e-16 -1.19754394e-16 -8.37033314e-16 -3.99181312e-17\n",
      " -3.99181312e-17  0.00000000e+00 -3.99181312e-16  3.59263181e-16\n",
      " -1.19754394e-16  2.49488320e-17  1.99590656e-16  3.19345050e-16\n",
      " -1.59672525e-16]\n",
      "\n",
      "Odchylenie standardowe cech:\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "\n",
    "print(\"Przed standaryzacją\")\n",
    "print_dataset_stats(X)\n",
    "X = scaler.transform(X)\n",
    "print(\"Po standaryzacji\")\n",
    "print_dataset_stats(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-usage",
   "metadata": {},
   "source": [
    "### Uczenie modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-friendship",
   "metadata": {},
   "source": [
    "Mając odpowiednio przygotowane dane, możemy przystąpić do procesu uczenia. Pierwszym krokiem będzie podział zbioru na część treningową (na której nauczymy model) oraz testową (na której przetestujemy jego jakość). Taki podział pozwala zmierzyć zdolność modelu do generalizacji - sprawdzamy jakość na danych, które nie były użyte do nauki, których \"model wcześniej nie widział\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "professional-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "effective-wound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (142, 13)\n",
      "X_test:  (36, 13)\n",
      "y_train:  (142,)\n",
      "y_test:  (36,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train: ', X_train.shape)\n",
    "print('X_test: ', X_test.shape)\n",
    "print('y_train: ', y_train.shape)\n",
    "print('y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-thinking",
   "metadata": {},
   "source": [
    "Finalnie jesteśmy gotowi stworzyć klasyfikator. Dla przykładu użyjemy algorytmu SVM. Przykłady innych modeli można znaleźć [tutaj](https://scikit-learn.org/stable/supervised_learning.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "distinguished-designation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-violin",
   "metadata": {},
   "source": [
    "Możemy go teraz użyć w celu predykcji nowych wartości:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "prostate-subject",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(X_test[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-radius",
   "metadata": {},
   "source": [
    "```{important}\n",
    "Istnieje wiele modeli uczenia maszynowego. Wybór odpowiedniego zależy od problemu który rozwiązujemy, danych które posiadamy, pożądanemu rezultatowi i warunkom działania (np. pożądana szybkość uczenia i inferencji).\n",
    "\n",
    "Do najpopularniejszych modeli nadzorowanych należą - drzewa decyzyjne (i lasy losowe), kNN, SVM, Naive Bayes, sieci neuronowe.\n",
    "\n",
    "Niestety, dokładne wprowadzenie w fascynującą dziedzinę modelu uczenia maszynowego leży poza zakresem tego laboratorium.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-programming",
   "metadata": {},
   "source": [
    "### Potoki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-leeds",
   "metadata": {},
   "source": [
    "W powyższym przykładzie po wczytaniu danych przetworzyliśmy je przez dwa algorytmy - `StandardScaler` i `SVM`. W przypadku bardziej rozbudowanego preprocessingu, niezwykle przydatna staje się możliwość łączenia wszystkich użytych mechanizmów w jeden potok:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "actual-elephant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()), ('svc', SVC())])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "X, y = load_wine(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "\n",
    "pipeline_classifier = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    SVC()\n",
    ")\n",
    "\n",
    "pipeline_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "accepted-dancing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_classifier.predict(X_test[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-jefferson",
   "metadata": {},
   "source": [
    "### Analiza jakości modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-medium",
   "metadata": {},
   "source": [
    "Na tym etapie posiadamy zbiór danych podzielony na część treningową i testową, oraz klasyfikator nauczony na częsci treningowej. Jak sprawdzić, jak dobrze jest on nauczony?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-mentor",
   "metadata": {},
   "source": [
    "Do określenia jakości modelu służy szereg metryk, różnych w zależności od problemu. \n",
    "\n",
    "W zadaniu klasyfikacji, standardowo używa się następujących miar wywodzących się z klasyfikacji binarnej:\n",
    "- accuracy, oznaczająca procent poprawnie oznaczonych przykładów\n",
    "- F1 - będąca średnią miar `precision` i `recall`, mierzących skłonności modelu do niepopełniania błędów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "official-paste",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9722222222222222\n",
      "F1:  0.9747545582047685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predicted = pipeline_classifier.predict(X_test)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_predicted))\n",
    "print('F1: ', f1_score(y_test, y_predicted, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-pipeline",
   "metadata": {},
   "source": [
    "Dokładniejsze informacje o jakości klasyfikacji możemy uzyskac np. przy pomocy metody `classification_report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "documentary-consciousness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 1.0,\n",
       "  'recall': 0.9166666666666666,\n",
       "  'f1-score': 0.9565217391304348,\n",
       "  'support': 12},\n",
       " '1': {'precision': 0.9375,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.967741935483871,\n",
       "  'support': 15},\n",
       " '2': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 9},\n",
       " 'accuracy': 0.9722222222222222,\n",
       " 'macro avg': {'precision': 0.9791666666666666,\n",
       "  'recall': 0.9722222222222222,\n",
       "  'f1-score': 0.9747545582047685,\n",
       "  'support': 36},\n",
       " 'weighted avg': {'precision': 0.9739583333333334,\n",
       "  'recall': 0.9722222222222222,\n",
       "  'f1-score': 0.9720663861617579,\n",
       "  'support': 36}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "classification_report(y_test, y_predicted, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-health",
   "metadata": {},
   "source": [
    "W przypadku zadania regresji, standardowo używaną miarą jest błąd średniokwadratowy (`ang. mean square error`). Więcej informacji o różnych rodzajach metryk jakości modelu - [tutaj](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-plymouth",
   "metadata": {},
   "source": [
    "### Sprawdzanie krzyżowe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-empty",
   "metadata": {},
   "source": [
    "Powyżej nauczyliśmy model klasyfikować - i to z bardzo dobrą jakością! \n",
    "\n",
    "Jednakże, nauczyliśmy nasz model na pewnym podzbiorze danych i przetestowaliśmy na innym. Nie mamy pewności, czy model sam w sobie wykazuje się dobrą jakością, czy to akurat ten specyficzny wybór podzbiorów danych daje tak dobre wyniki.\n",
    "\n",
    "Z pomocą przychodzi tutaj `sprawdzanie krzyżowe` `(ang. cross-validation)`. Jest to procedura polegająca na kilkukrotnym uruchomieniu procedury uczenia modelu, za każdym razem na innym podzbiorze danych. Uśredniony wynik takich kilku modeli pozwala z większą dokładnością wyrokować o jakości samego modelu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cosmetic-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X, y = load_wine(return_X_y=True)\n",
    "cv_results = cross_validate(\n",
    "    pipeline_classifier, \n",
    "    X, \n",
    "    y,\n",
    "    scoring='f1_macro'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "turkish-softball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.983504493924021"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-diamond",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Dostosowywanie parametrów"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-space",
   "metadata": {},
   "source": [
    "Praktycznie każdy z algorytmów uczenia maszynowego posiada pewne parametry (lub hiper-parametry), które wpływają na proces uczenia. W przypadku użytego algorytmu SVM są to np. rodzaj funkcji jądra i stopień regularyzacji. \n",
    "\n",
    "Odpowiednie dostosowanie parametrów algorytmu do danego problemu może znacząco poprawić jakość jego działania. \n",
    "\n",
    "Sklearn posiada zaimplementowanych kilka strategii poszukiwania najlepszych parametrów. Użyjemy tutaj najprostszego podejścia losowego:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "double-palmer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__kernel': 'linear', 'svc__C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "X, y = load_wine(return_X_y=True)\n",
    "\n",
    "param_distributions = {'svc__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                       'svc__C': [0.1, 0.5, 1, 2, 4]}\n",
    "\n",
    "# now create a searchCV object and fit it to the data\n",
    "search = RandomizedSearchCV(estimator=pipeline_classifier,\n",
    "                            n_iter=5,\n",
    "                            param_distributions=param_distributions)\n",
    "search.fit(X, y)\n",
    "\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-indication",
   "metadata": {},
   "source": [
    "Mechanizm wykonuje ilosc powtórzeń zadaną przez argument `n_iter` i losuje za każdym razem wartości parametrów spośród podanych. Dla każdego z nich wykonuje cross-walidację. Możemy też przeanalizować dokładne wyniki tego procesu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "conceptual-bermuda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00537829, 0.00644789, 0.00556135, 0.00395641, 0.00475116]),\n",
       " 'std_fit_time': array([0.00302507, 0.00417539, 0.00360711, 0.0018147 , 0.00253776]),\n",
       " 'mean_score_time': array([0.00384507, 0.00235186, 0.00214186, 0.00119901, 0.00100121]),\n",
       " 'std_score_time': array([0.00432281, 0.00146971, 0.00099259, 0.00075927, 0.00032661]),\n",
       " 'param_svc__kernel': masked_array(data=['rbf', 'linear', 'linear', 'linear', 'poly'],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_svc__C': masked_array(data=[0.1, 2, 0.1, 4, 2],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'svc__kernel': 'rbf', 'svc__C': 0.1},\n",
       "  {'svc__kernel': 'linear', 'svc__C': 2},\n",
       "  {'svc__kernel': 'linear', 'svc__C': 0.1},\n",
       "  {'svc__kernel': 'linear', 'svc__C': 4},\n",
       "  {'svc__kernel': 'poly', 'svc__C': 2}],\n",
       " 'split0_test_score': array([0.97222222, 0.94444444, 0.97222222, 0.94444444, 0.91666667]),\n",
       " 'split1_test_score': array([0.97222222, 0.97222222, 0.94444444, 0.97222222, 0.97222222]),\n",
       " 'split2_test_score': array([0.94444444, 0.97222222, 0.97222222, 0.97222222, 1.        ]),\n",
       " 'split3_test_score': array([0.94285714, 0.97142857, 1.        , 0.97142857, 0.94285714]),\n",
       " 'split4_test_score': array([1.        , 0.97142857, 0.97142857, 0.97142857, 0.97142857]),\n",
       " 'mean_test_score': array([0.96634921, 0.96634921, 0.97206349, 0.96634921, 0.96063492]),\n",
       " 'std_test_score': array([0.02113318, 0.01095813, 0.01757108, 0.01095813, 0.02845922]),\n",
       " 'rank_test_score': array([2, 2, 1, 2, 5], dtype=int32)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-angola",
   "metadata": {},
   "source": [
    "Parametry modelu sprawdzić możemy przy pomocy metody `get_params()` lub [w dokumentacji](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "superior-master",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler', StandardScaler()), ('svc', SVC())],\n",
       " 'verbose': False,\n",
       " 'standardscaler': StandardScaler(),\n",
       " 'svc': SVC(),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'svc__C': 1.0,\n",
       " 'svc__break_ties': False,\n",
       " 'svc__cache_size': 200,\n",
       " 'svc__class_weight': None,\n",
       " 'svc__coef0': 0.0,\n",
       " 'svc__decision_function_shape': 'ovr',\n",
       " 'svc__degree': 3,\n",
       " 'svc__gamma': 'scale',\n",
       " 'svc__kernel': 'rbf',\n",
       " 'svc__max_iter': -1,\n",
       " 'svc__probability': False,\n",
       " 'svc__random_state': None,\n",
       " 'svc__shrinking': True,\n",
       " 'svc__tol': 0.001,\n",
       " 'svc__verbose': False}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_classifier.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-beaver",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cubic-toolbox",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "shared-graham",
   "metadata": {},
   "source": [
    "## Zadania\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-drill",
   "metadata": {},
   "source": [
    "1\\. (1 pkt) Przy pomocy sklearn, wczytaj zbiór danych [California Housing](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset) i wyświetl jego przykładowe kilka rekordów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "understanding-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TUTAJ UMIEŚĆ KOD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-president",
   "metadata": {},
   "source": [
    "2\\. (1.5 pkt) Przy pomocy biblioteki Pandas Profiling przeanalizuj w/w zbiór i odpowiedz na następujące pytania:\n",
    "\n",
    "- ile znajduje się w zbiorze cech kategorycznych, a ile numerycznych? \n",
    "- czy zmienna wyjściowa jest kategoryczna, czy numeryczna?\n",
    "- czy rozpatrujemy problem klasyfikacji, klasteryzacji czy regresji?\n",
    "- ile w zbiorze jest brakujących wartości?\n",
    "- czy któraś z cech koreluje ze zmienną wyjściową? Jeśli tak - która?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "metallic-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUTAJ UMIEŚC ODPOWIEDZI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-waterproof",
   "metadata": {},
   "source": [
    "3\\. (2 pkt) stwórz pipeline składający się z modułu standaryzacji i estymatora - w zależności czy problem dotyczy klasyfikacji czy regresji, użyj [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) lub [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "crucial-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUTAJ UMIEŚĆ KOD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-termination",
   "metadata": {},
   "source": [
    "4\\. (4 pkt) używając sprawdzianu krzyżowego z 10 foldami (sprawdź odpowiedni parametr w [dokumentacji](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html)) sprawdź jakość predykcji, używając odpowiednich do zadania metryk (wybierz odpowiednią spośród tych [tutaj](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "indoor-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUTAJ UMIEŚĆ KOD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-radar",
   "metadata": {},
   "source": [
    "5\\. (3 pkt) Używając cross-walidacji, porównaj jakość modelu używającego i nieużywającego standaryzacji cech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pressed-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUTAJ UMIEŚC KOD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-outdoors",
   "metadata": {},
   "source": [
    "6\\. (3.5 pkt) Używając metody [GridSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) sprawdź, jakie parametry modelu najlepiej pasują do rozwiązywanego problemu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-comparative",
   "metadata": {},
   "source": [
    "```{important}\n",
    "Pamiętaj, że mechanizm GridSearch przeszukuje wszystkie możliwe kombinacje podanych parametrów. Nie podawaj ich zbyt wiele, by skończyć zadanie w sensownym czasie.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "metropolitan-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUTAJ UMIEŚĆ KOD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
